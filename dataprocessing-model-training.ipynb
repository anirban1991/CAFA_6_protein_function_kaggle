{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","name":"dataprocessing"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"},{"sourceId":14033853,"sourceType":"datasetVersion","datasetId":8936736}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==2.7.0\n!pip install torch-geometric\n!pip install biopython\n!pip install obonet\n!pip install networkx\n!pip install pandas\n!pip install numpy\n!pip install matplotlib\n!pip install seaborn\n!pip install scipy\n!pip install scikit-learn\n!pip install fair-esm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yg7HmzhSVM8L","outputId":"4c74257c-3122-4d26-da06-2e732cb1a6dd","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:55:57.389399Z","iopub.execute_input":"2025-12-07T22:55:57.389637Z","iopub.status.idle":"2025-12-07T22:59:17.900168Z","shell.execute_reply.started":"2025-12-07T22:55:57.389618Z","shell.execute_reply":"2025-12-07T22:59:17.899242Z"}},"outputs":[{"name":"stdout","text":"Collecting torch==2.7.0\n  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (4.15.0)\nCollecting sympy>=1.13.3 (from torch==2.7.0)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.3.0 (from torch==2.7.0)\n  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0) (75.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.0) (3.0.3)\nDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 triton-3.3.0\nCollecting torch-geometric\n  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.13.2)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.10.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.1.3)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.6.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.22.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.10.5)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.7.0\nCollecting biopython\n  Downloading biopython-1.86-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->biopython) (2024.2.0)\nDownloading biopython-1.86-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: biopython\nSuccessfully installed biopython-1.86\nCollecting obonet\n  Downloading obonet-1.1.1-py3-none-any.whl.metadata (6.7 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from obonet) (3.5)\nDownloading obonet-1.1.1-py3-none-any.whl (9.2 kB)\nInstalling collected packages: obonet\nSuccessfully installed obonet-1.1.1\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->matplotlib) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.24.0,>=1.17->seaborn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\nRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy) (2024.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nCollecting fair-esm\n  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\nDownloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fair-esm\nSuccessfully installed fair-esm-2.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\" # avoid fragmentation\nimport torch\nimport torch_geometric\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GCNConv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport Bio\nfrom Bio import SeqIO\nimport obonet\nimport gc\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport random\nimport esm\n","metadata":{"id":"GGPDDs_kXqU9","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:17.901857Z","iopub.execute_input":"2025-12-07T22:59:17.902194Z","iopub.status.idle":"2025-12-07T22:59:26.077426Z","shell.execute_reply.started":"2025-12-07T22:59:17.902171Z","shell.execute_reply":"2025-12-07T22:59:26.076828Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"obo_path = '/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo'\nfasta_path = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta'\nterm_path = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv'\ntaxonomy_path = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_taxonomy.tsv'","metadata":{"id":"R7rUQCNdVug8","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.078167Z","iopub.execute_input":"2025-12-07T22:59:26.078592Z","iopub.status.idle":"2025-12-07T22:59:26.082927Z","shell.execute_reply.started":"2025-12-07T22:59:26.078564Z","shell.execute_reply":"2025-12-07T22:59:26.082114Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"LARGEST_FASTA_SEQ_LEN = 8922\nESM_EMBEDDING_DIM = 320\nPCA_TARGET_DIM = 16","metadata":{"id":"DGqwUSV6v0pF","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.083917Z","iopub.execute_input":"2025-12-07T22:59:26.084162Z","iopub.status.idle":"2025-12-07T22:59:26.099127Z","shell.execute_reply.started":"2025-12-07T22:59:26.084144Z","shell.execute_reply":"2025-12-07T22:59:26.098357Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"term_df = pd.read_csv(term_path, sep='\\t')\nterm_df.head(), len(term_df[\"term\"].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.100803Z","iopub.execute_input":"2025-12-07T22:59:26.101336Z","iopub.status.idle":"2025-12-07T22:59:26.450015Z","shell.execute_reply.started":"2025-12-07T22:59:26.101316Z","shell.execute_reply":"2025-12-07T22:59:26.449405Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"INQOe3ORgEhq","outputId":"06dffad4-67af-4570-ba3b-cbb65053105f"},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(  EntryID        term aspect\n 0  Q5W0B1  GO:0000785      C\n 1  Q5W0B1  GO:0004842      F\n 2  Q5W0B1  GO:0051865      P\n 3  Q5W0B1  GO:0006275      P\n 4  Q5W0B1  GO:0006513      P,\n 26125)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"taxonomy_df = pd.read_csv(taxonomy_path, sep='\\t', names=['EntryID', 'taxonomyID'])\ntaxonomy_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.450827Z","iopub.execute_input":"2025-12-07T22:59:26.451115Z","iopub.status.idle":"2025-12-07T22:59:26.504636Z","shell.execute_reply.started":"2025-12-07T22:59:26.451097Z","shell.execute_reply":"2025-12-07T22:59:26.504076Z"},"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ICSCnvj0gEhq","outputId":"15f82984-c0ff-4ea7-9385-8bd43a92e8bc"},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      EntryID  taxonomyID\n0  A0A0C5B5G6        9606\n1      A0JNW5        9606\n2      A0JP26        9606\n3      A0PK11        9606\n4      A1A4S6        9606","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A0C5B5G6</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0JNW5</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0JP26</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0PK11</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A1A4S6</td>\n      <td>9606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# def get_processed_fasta_df(fasta_data, term_df):\n#     fasta_dict_list = []\n#     term_set = set(term_df.tolist())\n#     for fasta_seq in fasta_data:\n#         entry = fasta_seq.id.split('|')[1] if '|' in fasta_seq.id else fasta_seq.id\n#         if entry in term_set:\n#             fasta_dict_list.append({\n#                 \"EntryID\": entry,\n#                 \"fasta_sequence\": str(fasta_seq.seq)\n#             })\n\n#     return pd.DataFrame(fasta_dict_list)\n\n\ndef sample_tsv(tsv_df, sample_frac=0.05, random_state=42):\n    \"\"\"\n    Read a TSV file and sample based on unique EntryID.\n    Pulls in all associated rows for sampled EntryIDs.\n    \"\"\"\n    df = tsv_df\n    unique_ids = df['EntryID'].unique()\n    sample_size = max(1, int(len(unique_ids) * sample_frac))\n    sampled_ids = random.sample(list(unique_ids), sample_size)\n    sampled_df = df[df['EntryID'].isin(sampled_ids)]\n    print(f\"Sampled {len(sampled_df)} rows from {len(unique_ids)} unique EntryIDs\")\n    return sampled_df\n\n\ndef get_processed_fasta_df(fasta_data):\n    fasta_dict_list = []\n    for fasta_seq in fasta_data:\n        entry = fasta_seq.id.split('|')[1] if '|' in fasta_seq.id else fasta_seq.id\n        fasta_dict_list.append({\n                \"EntryID\": entry,\n                \"fasta_sequence\": str(fasta_seq.seq)\n            })\n\n    return pd.DataFrame(fasta_dict_list)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.505394Z","iopub.execute_input":"2025-12-07T22:59:26.505621Z","iopub.status.idle":"2025-12-07T22:59:26.511519Z","shell.execute_reply.started":"2025-12-07T22:59:26.505604Z","shell.execute_reply":"2025-12-07T22:59:26.510779Z"},"id":"Cs-etgEDgEhq"},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Get Merged DF FULL (includes batching to fit embeddings into GPU and offloads to CPU)","metadata":{"id":"3hKLO3KwgEhr"}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\nmodel = model.to(device)\nmodel = model.half()\nmodel.eval()\nbatch_converter = alphabet.get_batch_converter()\n\ndef generate_protein_embeddings_esm_batch(seq_df, seq_col='Sequence', entryid_col='EntryID',\n                                              target_dim=16, batch_size=1, use_fp16=True):\n    \"\"\"\n    Memory-optimized ESM embedding generation for proteins.\n    Processes small batches and moves embeddings to CPU immediately.\n    \"\"\"\n    sequences = seq_df[seq_col].tolist()\n    entry_ids = seq_df[entryid_col].tolist()\n    print(f\"sequences: {len(sequences)} entry_ids {len(entry_ids)}\")\n\n    all_embeddings = []\n    # print(len(sequences))\n    dtype = torch.float16 if use_fp16 else torch.float32\n    for i in range(0, len(sequences), batch_size):\n        try:\n            batch_seqs = sequences[i:i+batch_size]\n            batch_labels = entry_ids[i:i+batch_size]\n            if len(batch_seqs[0]) > LARGEST_FASTA_SEQ_LEN:\n                print(f\"length of batch seqs is: {len(batch_seqs[0])}\")\n                # Split the sequence to be max length LARGEST_FASTA_SEQ_LEN (will always be len 1 batch), this helps avoid the loss of information\n                curr_seq = batch_seqs[0]\n                embeddings_list = []\n                for i in range(0, len( batch_seqs[0]), LARGEST_FASTA_SEQ_LEN):\n                  curr_seq = batch_seqs[0][i:i+LARGEST_FASTA_SEQ_LEN]\n                  curr_seq_embedding = get_sequence_embedding_esm(batch_labels, [curr_seq], dtype)\n                  embeddings_list.append(curr_seq_embedding)\n                # Average the embeddings_list since the long sequences were broken down into smaller chunks\n                seq_embeddings = np.mean(embeddings_list, axis=0)\n\n            else:\n              seq_embeddings = get_sequence_embedding_esm(batch_labels, batch_seqs, dtype)\n\n            all_embeddings.append(seq_embeddings)\n            del seq_embeddings\n        except Exception as e:\n            print(e)\n            print(len(batch_seqs[0]))\n            print(batch_seqs)\n\n\n    raw_embeddings = np.vstack(all_embeddings)\n    # Mitigate memory constraints\n    gc.collect()\n    torch.cuda.empty_cache()\n    torch.cuda.ipc_collect()\n    torch.cuda.reset_peak_memory_stats()\n\n    col_names = [f\"prot_emb_{i}\" for i in range(320)]\n    emb_df = pd.DataFrame(raw_embeddings, index=entry_ids, columns=col_names)\n    emb_df.index.name = entryid_col\n\n    return emb_df\n\n\ndef get_sequence_embedding_esm(batch_labels, batch_seqs, dtype):\n    batch_data = [(label, seq) for label, seq in zip(batch_labels, batch_seqs)]\n    _, _, batch_tokens = batch_converter(batch_data)\n    batch_tokens = batch_tokens.to(device)\n    with torch.no_grad():\n      with torch.autocast(device_type=\"cuda\", dtype=dtype):\n          results = model(batch_tokens, repr_layers=[model.num_layers], return_contacts=False)\n          token_embeddings = results[\"representations\"][model.num_layers]  # (B, L, D)\n          # Mean pool over sequence length\n          attention_mask = batch_tokens != alphabet.padding_idx\n          masked_embeddings = token_embeddings * attention_mask.unsqueeze(-1)\n          seq_lengths = attention_mask.sum(dim=1).unsqueeze(-1)\n          seq_embeddings = (masked_embeddings.sum(dim=1) / seq_lengths).cpu().float().numpy()\n          del batch_tokens, token_embeddings, masked_embeddings, results, attention_mask\n          return seq_embeddings\n\n\ndef apply_pca_to_esm_embeddings(esm_embeddings_df:pd.DataFrame, target_dim=16):\n    '''\n    Helper method \n    '''\n    emb_cols = [c for c in esm_embeddings_df.columns if c.startswith(\"prot_emb\")]\n    \n    tensor_list = [ \n        torch.tensor(row[emb_cols].values.astype(\"float16\"), dtype=torch.float16)\n        for _, row in esm_embeddings_df.iterrows()\n    ]\n    \n    pca = PCA(n_components=PCA_TARGET_DIM)\n    tensor_list_transformed = pca.fit_transform(tensor_list)\n    \n    # Intialize dictionary where we use EntryID for joining with all the other data\n    embeddings_dict = { \"EntryID\": [] }\n    # Initialize empty PCA embeddings for the pd.DataFrame\n    for i in range(PCA_TARGET_DIM):\n        embeddings_dict[f\"emb_{i}\"] =  []\n        \n    # Append EntryID's and embeddings to the dictionary for the dataframe\n    for i, r in enumerate(tensor_list_transformed):\n        curr_entry_id = esm_embeddings_df[\"EntryID\"][i]\n        embeddings_dict[\"EntryID\"].append(curr_entry_id)\n        for j in range(PCA_TARGET_DIM):\n            embeddings_dict[f\"emb_{j}\"].append(r[j])\n\n    pca_embeddings_df = pd.DataFrame(embeddings_dict)\n    return pca_embeddings_df\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.512310Z","iopub.execute_input":"2025-12-07T22:59:26.512568Z","iopub.status.idle":"2025-12-07T22:59:27.112645Z","shell.execute_reply.started":"2025-12-07T22:59:26.512541Z","shell.execute_reply":"2025-12-07T22:59:27.111881Z"},"id":"bGhEVeBagEhr"},"outputs":[{"name":"stdout","text":"Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D.pt\nDownloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t6_8M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D-contact-regression.pt\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"file_name = \"/kaggle/input/fasta-embeddings-final/fasta_embeddings_final.csv\"\nembeddings_processed = True\n\ndef get_merged_df_full(file_name, batch_size=250, embeddings_processed=False):\n    \"\"\"\n    Merge term.tsv, fasta data, taxonomy data as well as nodes in the obo graph.\n    \"\"\"\n    term_df = pd.read_csv(term_path, sep='\\t')\n    term_df = term_df\n    taxonomy_df = pd.read_csv(taxonomy_path, sep='\\t', names=['EntryID', 'taxonomyID'])\n    fasta_data = list(SeqIO.parse(fasta_path, \"fasta\"))\n\n    entry_ids = list(term_df['EntryID'])\n    all_batches = []\n    if not embeddings_processed:\n      for i in range(0, len(entry_ids), batch_size):\n          total_processed = i\n          print(f\"Total processed: {total_processed}, {i//batch_size} batch\")\n\n          # Batch the EntryIDs\n          entry_batch = list(set(entry_ids[i:i+batch_size]))\n\n          curr_term_df = term_df[i:i+batch_size]\n          fasta_df_batch = get_processed_fasta_df(fasta_data, curr_term_df['EntryID'])\n          fasta_emb_df_batch = generate_protein_embeddings_esm_batch(\n              fasta_df_batch,\n              \"fasta_sequence\"\n          )\n\n\n          all_batches.append(fasta_emb_df_batch)\n\n          full_df = pd.concat(all_batches, ignore_index=False)\n          full_df.to_csv(\"fasta_embeddings.csv\", index=True)\n\n    else:\n        full_df = pd.read_csv(file_name)\n        print(full_df.head())\n        \n    fasta_emb_df = apply_pca_to_esm_embeddings(full_df)\n    \n    # TODO add embeddings in getting merged_df\n    merged_df = pd.merge(term_df, fasta_emb_df, on=\"EntryID\", how='left')\n    merged_df = pd.merge(merged_df, taxonomy_df, on=\"EntryID\", how=\"left\")\n    graph = obonet.read_obo(obo_path)\n    edges_list = []\n    for node_id, data in graph.nodes(data=True):\n        for parent_id in data.get(\"is_a\", []):\n            edges_list.append({\n                    \"term\": node_id,\n                    \"parent\": parent_id,\n                    \"relation\": data.get('relation', 'is_a'),\n                    \"name\": data[\"name\"],\n                    \"namespace\": data[\"namespace\"],\n                    \"def\": data[\"def\"],\n                    \"synonym\": data.get(\"synonym\", [])\n                    \n                })\n    edges_df = pd.DataFrame(edges_list)\n    return merged_df, edges_df\n\nprotein_function_df, graph_df = get_merged_df_full(file_name, embeddings_processed=embeddings_processed)\nlen(protein_function_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:02:30.602475Z","iopub.execute_input":"2025-12-07T23:02:30.602996Z","iopub.status.idle":"2025-12-07T23:03:32.767804Z","shell.execute_reply.started":"2025-12-07T23:02:30.602970Z","shell.execute_reply":"2025-12-07T23:03:32.767206Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"nH7Ng5SXgEhr","outputId":"ddcef6f2-99d6-49db-e0d7-bababde1dda8"},"outputs":[{"name":"stdout","text":"  EntryID  prot_emb_0  prot_emb_1  prot_emb_2  prot_emb_3  prot_emb_4  \\\n0  P86164    0.063601    0.090173    0.272553    0.045446   -0.024562   \n1  P84910    0.164426   -0.128475    0.244240    0.068856   -0.031558   \n2  P83012    0.126772   -0.093400    0.216583    0.056300   -0.058426   \n3  P83246    0.039001   -0.228608    0.207255    0.138270    0.081464   \n4  P86133   -0.063519    0.141610    0.168906   -0.003960   -0.064855   \n\n   prot_emb_5  prot_emb_6  prot_emb_7  prot_emb_8  ...  prot_emb_310  \\\n0   -0.087723   -0.097689   -0.002640   -0.085523  ...      0.121198   \n1   -0.102609   -0.108406   -0.071888   -0.022300  ...      0.094619   \n2    0.006500   -0.052936   -0.012787   -0.090959  ...      0.024688   \n3   -0.122376   -0.169814   -0.090188   -0.169230  ...     -0.015823   \n4   -0.166769    0.018469    0.077215    0.058494  ...      0.147194   \n\n   prot_emb_311  prot_emb_312  prot_emb_313  prot_emb_314  prot_emb_315  \\\n0      0.150969      0.038082     -0.035188      0.107149     -0.139242   \n1     -0.008651      0.114921     -0.001714      0.107898      0.074844   \n2     -0.042868      0.107209      0.052345      0.101476      0.072974   \n3      0.006365      0.128541      0.029864      0.042600      0.003246   \n4      0.332067     -0.085424      0.030959      0.007410     -0.137569   \n\n   prot_emb_316  prot_emb_317  prot_emb_318  prot_emb_319  \n0     -0.068953      0.179406      0.029193      0.072149  \n1     -0.127740     -0.065333      0.162325     -0.015353  \n2      0.023981      0.138794     -0.027119     -0.144226  \n3      0.032807      0.189388      0.199859     -0.110070  \n4      0.025430      0.357189     -0.158802      0.058284  \n\n[5 rows x 321 columns]\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"537027"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"UNIQUE_TERMS = list(protein_function_df[\"term\"].unique())\nlen(UNIQUE_TERMS) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:53.153544Z","iopub.execute_input":"2025-12-07T23:04:53.153890Z","iopub.status.idle":"2025-12-07T23:04:53.198579Z","shell.execute_reply.started":"2025-12-07T23:04:53.153865Z","shell.execute_reply":"2025-12-07T23:04:53.197829Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"26125"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":" graph = obonet.read_obo(obo_path)\nedges_list = []\nfor node_id, data in graph.nodes(data=True):\n        for parent_id in data.get(\"is_a\", []):\n            edges_list.append({\n                    \"term\": node_id,\n                    \"parent\": parent_id,\n                    \"name\": data[\"name\"],\n                    \"namespace\": data[\"namespace\"],\n                    \"def\": data[\"def\"],\n                    \"synonym\": data.get(\"synonym\", [])\n                })\nedges_df = pd.DataFrame(edges_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:53.643582Z","iopub.execute_input":"2025-12-07T23:04:53.644112Z","iopub.status.idle":"2025-12-07T23:04:58.819725Z","shell.execute_reply.started":"2025-12-07T23:04:53.644088Z","shell.execute_reply":"2025-12-07T23:04:58.819139Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"ALL_SUBONTOLOGIES = graph_df[\"namespace\"].unique()\ngraph_df.head(\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:58.820763Z","iopub.execute_input":"2025-12-07T23:04:58.821040Z","iopub.status.idle":"2025-12-07T23:04:58.837159Z","shell.execute_reply.started":"2025-12-07T23:04:58.821022Z","shell.execute_reply":"2025-12-07T23:04:58.836567Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"         term      parent relation  \\\n0  GO:0000001  GO:0048308     is_a   \n1  GO:0000001  GO:0048311     is_a   \n2  GO:0000002  GO:0007005     is_a   \n3  GO:0000006  GO:0005385     is_a   \n4  GO:0000007  GO:0005385     is_a   \n\n                                                name           namespace  \\\n0                          mitochondrion inheritance  biological_process   \n1                          mitochondrion inheritance  biological_process   \n2                   mitochondrial genome maintenance  biological_process   \n3  high-affinity zinc transmembrane transporter a...  molecular_function   \n4  low-affinity zinc ion transmembrane transporte...  molecular_function   \n\n                                                 def  \\\n0  \"The distribution of mitochondria, including t...   \n1  \"The distribution of mitochondria, including t...   \n2  \"The maintenance of the structure and integrit...   \n3  \"Enables the transfer of zinc ions (Zn2+) from...   \n4  \"Enables the transfer of a solute or solutes f...   \n\n                                             synonym  \n0             [\"mitochondrial inheritance\" EXACT []]  \n1             [\"mitochondrial inheritance\" EXACT []]  \n2                                                 []  \n3  [\"high affinity zinc uptake transmembrane tran...  \n4                                                 []  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>parent</th>\n      <th>relation</th>\n      <th>name</th>\n      <th>namespace</th>\n      <th>def</th>\n      <th>synonym</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GO:0000001</td>\n      <td>GO:0048308</td>\n      <td>is_a</td>\n      <td>mitochondrion inheritance</td>\n      <td>biological_process</td>\n      <td>\"The distribution of mitochondria, including t...</td>\n      <td>[\"mitochondrial inheritance\" EXACT []]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GO:0000001</td>\n      <td>GO:0048311</td>\n      <td>is_a</td>\n      <td>mitochondrion inheritance</td>\n      <td>biological_process</td>\n      <td>\"The distribution of mitochondria, including t...</td>\n      <td>[\"mitochondrial inheritance\" EXACT []]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GO:0000002</td>\n      <td>GO:0007005</td>\n      <td>is_a</td>\n      <td>mitochondrial genome maintenance</td>\n      <td>biological_process</td>\n      <td>\"The maintenance of the structure and integrit...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GO:0000006</td>\n      <td>GO:0005385</td>\n      <td>is_a</td>\n      <td>high-affinity zinc transmembrane transporter a...</td>\n      <td>molecular_function</td>\n      <td>\"Enables the transfer of zinc ions (Zn2+) from...</td>\n      <td>[\"high affinity zinc uptake transmembrane tran...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GO:0000007</td>\n      <td>GO:0005385</td>\n      <td>is_a</td>\n      <td>low-affinity zinc ion transmembrane transporte...</td>\n      <td>molecular_function</td>\n      <td>\"Enables the transfer of a solute or solutes f...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"protein_function_df.head()","metadata":{"id":"mWU9VsYHx7oZ","outputId":"4e593628-7c94-4155-9111-bfdb21331e95","colab":{"base_uri":"https://localhost:8080/","height":771},"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:58.837750Z","iopub.execute_input":"2025-12-07T23:04:58.837963Z","iopub.status.idle":"2025-12-07T23:04:58.852239Z","shell.execute_reply.started":"2025-12-07T23:04:58.837947Z","shell.execute_reply":"2025-12-07T23:04:58.851560Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"  EntryID        term aspect     emb_0     emb_1     emb_2    emb_3     emb_4  \\\n0  Q5W0B1  GO:0000785      C -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n1  Q5W0B1  GO:0004842      F -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n2  Q5W0B1  GO:0051865      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n3  Q5W0B1  GO:0006275      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n4  Q5W0B1  GO:0006513      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n\n      emb_5     emb_6     emb_7    emb_8     emb_9    emb_10    emb_11  \\\n0 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n1 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n2 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n3 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n4 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n\n     emb_12  emb_13    emb_14    emb_15  taxonomyID  \n0 -0.117404 -0.2487 -0.039927  0.179385        9606  \n1 -0.117404 -0.2487 -0.039927  0.179385        9606  \n2 -0.117404 -0.2487 -0.039927  0.179385        9606  \n3 -0.117404 -0.2487 -0.039927  0.179385        9606  \n4 -0.117404 -0.2487 -0.039927  0.179385        9606  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>term</th>\n      <th>aspect</th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>emb_10</th>\n      <th>emb_11</th>\n      <th>emb_12</th>\n      <th>emb_13</th>\n      <th>emb_14</th>\n      <th>emb_15</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q5W0B1</td>\n      <td>GO:0000785</td>\n      <td>C</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q5W0B1</td>\n      <td>GO:0004842</td>\n      <td>F</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q5W0B1</td>\n      <td>GO:0051865</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q5W0B1</td>\n      <td>GO:0006275</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q5W0B1</td>\n      <td>GO:0006513</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"N_LARGEST = 10\ntop_terms = protein_function_df['term'].value_counts().nlargest(N_LARGEST).index\nprotein_function_top_terms_df = protein_function_df[protein_function_df['term'].isin(top_terms)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:58.853552Z","iopub.execute_input":"2025-12-07T23:04:58.853755Z","iopub.status.idle":"2025-12-07T23:04:58.960409Z","shell.execute_reply.started":"2025-12-07T23:04:58.853741Z","shell.execute_reply":"2025-12-07T23:04:58.959873Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"len(protein_function_top_terms_df), len(protein_function_df), len(graph_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:58.960986Z","iopub.execute_input":"2025-12-07T23:04:58.961185Z","iopub.status.idle":"2025-12-07T23:04:58.966189Z","shell.execute_reply.started":"2025-12-07T23:04:58.961169Z","shell.execute_reply":"2025-12-07T23:04:58.965602Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(100851, 537027, 62410)"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"### Create set of embedding from the graph edges using GCN","metadata":{"id":"W3yvSIjBY5Bf"}},{"cell_type":"code","source":"class SimpleGCN(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim):\n        super(SimpleGCN, self).__init__()\n        self.conv1 = GCNConv(in_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, out_dim)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = self.conv2(x, edge_index)\n        return x\n  \ndef init_subontology_GCNs(embed_dim=16, hidden_dim=32, out_dim=16):\n    graph_subontology_dict = {\n       subontology: SimpleGCN(embed_dim, hidden_dim, out_dim) for subontology in ALL_SUBONTOLOGIES\n    }\n    return graph_subontology_dict\n\ndef get_subontology_graph_dfs(graph_df):\n    subontology_graph_dfs = {\n       subontology: graph_df[graph_df[\"namespace\"]==subontology] for subontology in ALL_SUBONTOLOGIES\n    }\n    return subontology_graph_dfs\n  \nsubontology_GCNs, subontology_graph_dfs = init_subontology_GCNs(), get_subontology_graph_dfs(graph_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:59.120105Z","iopub.execute_input":"2025-12-07T23:04:59.120304Z","iopub.status.idle":"2025-12-07T23:04:59.192055Z","shell.execute_reply.started":"2025-12-07T23:04:59.120289Z","shell.execute_reply":"2025-12-07T23:04:59.191479Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"protein_function_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:01.636316Z","iopub.execute_input":"2025-12-07T23:05:01.636898Z","iopub.status.idle":"2025-12-07T23:05:01.650769Z","shell.execute_reply.started":"2025-12-07T23:05:01.636872Z","shell.execute_reply":"2025-12-07T23:05:01.650231Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"  EntryID        term aspect     emb_0     emb_1     emb_2    emb_3     emb_4  \\\n0  Q5W0B1  GO:0000785      C -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n1  Q5W0B1  GO:0004842      F -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n2  Q5W0B1  GO:0051865      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n3  Q5W0B1  GO:0006275      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n4  Q5W0B1  GO:0006513      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n\n      emb_5     emb_6     emb_7    emb_8     emb_9    emb_10    emb_11  \\\n0 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n1 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n2 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n3 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n4 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n\n     emb_12  emb_13    emb_14    emb_15  taxonomyID  \n0 -0.117404 -0.2487 -0.039927  0.179385        9606  \n1 -0.117404 -0.2487 -0.039927  0.179385        9606  \n2 -0.117404 -0.2487 -0.039927  0.179385        9606  \n3 -0.117404 -0.2487 -0.039927  0.179385        9606  \n4 -0.117404 -0.2487 -0.039927  0.179385        9606  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>term</th>\n      <th>aspect</th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>emb_10</th>\n      <th>emb_11</th>\n      <th>emb_12</th>\n      <th>emb_13</th>\n      <th>emb_14</th>\n      <th>emb_15</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q5W0B1</td>\n      <td>GO:0000785</td>\n      <td>C</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q5W0B1</td>\n      <td>GO:0004842</td>\n      <td>F</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q5W0B1</td>\n      <td>GO:0051865</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q5W0B1</td>\n      <td>GO:0006275</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q5W0B1</td>\n      <td>GO:0006513</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"def group_terms_and_aspects(protein_function_df):\n    protein_function_grouped_df = (\n        protein_function_df\n            .groupby(\"EntryID\")\n            .agg({\n                \"term\": list,                     \n                \"aspect\": list,                   \n                **{c: \"first\" for c in protein_function_top_terms_df.columns \n                   if c.startswith(\"emb_\")},      \n                \"taxonomyID\": \"first\"            \n            })\n            .rename(columns={\"term\": \"output_terms\"})\n            .reset_index()\n    )\n    return protein_function_grouped_df\n\nprotein_function_grouped_df = group_terms_and_aspects(protein_function_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:02.967137Z","iopub.execute_input":"2025-12-07T23:05:02.967819Z","iopub.status.idle":"2025-12-07T23:05:05.331288Z","shell.execute_reply.started":"2025-12-07T23:05:02.967798Z","shell.execute_reply":"2025-12-07T23:05:05.330682Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"protein_function_grouped_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:09.602361Z","iopub.execute_input":"2025-12-07T23:05:09.602902Z","iopub.status.idle":"2025-12-07T23:05:09.619715Z","shell.execute_reply.started":"2025-12-07T23:05:09.602878Z","shell.execute_reply":"2025-12-07T23:05:09.619010Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"      EntryID  output_terms aspect     emb_0     emb_1     emb_2     emb_3  \\\n0  A0A023FBW4  [GO:0019958]    [F] -0.733679 -0.278833 -0.739130 -0.129298   \n1  A0A023FBW7  [GO:0019957]    [F] -0.677593 -0.401437 -0.250645  0.016632   \n2  A0A023FDY8  [GO:0019957]    [F] -0.652475 -0.402101 -0.241203  0.076115   \n3  A0A023FF81  [GO:0019958]    [F] -0.550702 -0.327903 -0.613980 -0.264536   \n4  A0A023FFB5  [GO:0019957]    [F] -0.633638 -0.376555 -0.319808 -0.284030   \n\n      emb_4     emb_5     emb_6     emb_7     emb_8     emb_9    emb_10  \\\n0  0.640625  0.608326  0.276888  0.059629  0.456924 -0.223931  0.269701   \n1  0.365204  1.118803  0.574566 -0.098997  0.702530 -0.231559  0.155171   \n2  0.370869  1.122666  0.586032 -0.069793  0.735825 -0.261511  0.230517   \n3  0.529165  0.625794  0.384368 -0.124693  0.377998 -0.150738  0.158927   \n4  0.645544  1.141829  0.553369 -0.213995  0.667949 -0.399849  0.135954   \n\n     emb_11    emb_12    emb_13    emb_14    emb_15  taxonomyID  \n0 -0.287853 -0.389044 -0.086320  0.318142  0.208756       34607  \n1 -0.124747  0.052744 -0.021441  0.258956  0.208436       34607  \n2 -0.101076  0.027873 -0.013094  0.264486  0.208656       34607  \n3 -0.375993 -0.408175 -0.077548  0.325447  0.130539       34607  \n4 -0.303759 -0.021841 -0.024281  0.311488  0.099055       34607  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>output_terms</th>\n      <th>aspect</th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>emb_10</th>\n      <th>emb_11</th>\n      <th>emb_12</th>\n      <th>emb_13</th>\n      <th>emb_14</th>\n      <th>emb_15</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A023FBW4</td>\n      <td>[GO:0019958]</td>\n      <td>[F]</td>\n      <td>-0.733679</td>\n      <td>-0.278833</td>\n      <td>-0.739130</td>\n      <td>-0.129298</td>\n      <td>0.640625</td>\n      <td>0.608326</td>\n      <td>0.276888</td>\n      <td>0.059629</td>\n      <td>0.456924</td>\n      <td>-0.223931</td>\n      <td>0.269701</td>\n      <td>-0.287853</td>\n      <td>-0.389044</td>\n      <td>-0.086320</td>\n      <td>0.318142</td>\n      <td>0.208756</td>\n      <td>34607</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0A023FBW7</td>\n      <td>[GO:0019957]</td>\n      <td>[F]</td>\n      <td>-0.677593</td>\n      <td>-0.401437</td>\n      <td>-0.250645</td>\n      <td>0.016632</td>\n      <td>0.365204</td>\n      <td>1.118803</td>\n      <td>0.574566</td>\n      <td>-0.098997</td>\n      <td>0.702530</td>\n      <td>-0.231559</td>\n      <td>0.155171</td>\n      <td>-0.124747</td>\n      <td>0.052744</td>\n      <td>-0.021441</td>\n      <td>0.258956</td>\n      <td>0.208436</td>\n      <td>34607</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A023FDY8</td>\n      <td>[GO:0019957]</td>\n      <td>[F]</td>\n      <td>-0.652475</td>\n      <td>-0.402101</td>\n      <td>-0.241203</td>\n      <td>0.076115</td>\n      <td>0.370869</td>\n      <td>1.122666</td>\n      <td>0.586032</td>\n      <td>-0.069793</td>\n      <td>0.735825</td>\n      <td>-0.261511</td>\n      <td>0.230517</td>\n      <td>-0.101076</td>\n      <td>0.027873</td>\n      <td>-0.013094</td>\n      <td>0.264486</td>\n      <td>0.208656</td>\n      <td>34607</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A023FF81</td>\n      <td>[GO:0019958]</td>\n      <td>[F]</td>\n      <td>-0.550702</td>\n      <td>-0.327903</td>\n      <td>-0.613980</td>\n      <td>-0.264536</td>\n      <td>0.529165</td>\n      <td>0.625794</td>\n      <td>0.384368</td>\n      <td>-0.124693</td>\n      <td>0.377998</td>\n      <td>-0.150738</td>\n      <td>0.158927</td>\n      <td>-0.375993</td>\n      <td>-0.408175</td>\n      <td>-0.077548</td>\n      <td>0.325447</td>\n      <td>0.130539</td>\n      <td>34607</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0A023FFB5</td>\n      <td>[GO:0019957]</td>\n      <td>[F]</td>\n      <td>-0.633638</td>\n      <td>-0.376555</td>\n      <td>-0.319808</td>\n      <td>-0.284030</td>\n      <td>0.645544</td>\n      <td>1.141829</td>\n      <td>0.553369</td>\n      <td>-0.213995</td>\n      <td>0.667949</td>\n      <td>-0.399849</td>\n      <td>0.135954</td>\n      <td>-0.303759</td>\n      <td>-0.021841</td>\n      <td>-0.024281</td>\n      <td>0.311488</td>\n      <td>0.099055</td>\n      <td>34607</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"protein_function_grouped_df[protein_function_grouped_df[\"EntryID\"] == \"Q5W0B1\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:11.700612Z","iopub.execute_input":"2025-12-07T23:05:11.701332Z","iopub.status.idle":"2025-12-07T23:05:11.727633Z","shell.execute_reply.started":"2025-12-07T23:05:11.701308Z","shell.execute_reply":"2025-12-07T23:05:11.726710Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"      EntryID                                       output_terms  \\\n48432  Q5W0B1  [GO:0000785, GO:0004842, GO:0051865, GO:000627...   \n\n                      aspect     emb_0     emb_1     emb_2    emb_3     emb_4  \\\n48432  [C, F, P, P, P, F, F] -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n\n          emb_5     emb_6     emb_7    emb_8     emb_9    emb_10    emb_11  \\\n48432 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n\n         emb_12  emb_13    emb_14    emb_15  taxonomyID  \n48432 -0.117404 -0.2487 -0.039927  0.179385        9606  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>output_terms</th>\n      <th>aspect</th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>emb_10</th>\n      <th>emb_11</th>\n      <th>emb_12</th>\n      <th>emb_13</th>\n      <th>emb_14</th>\n      <th>emb_15</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>48432</th>\n      <td>Q5W0B1</td>\n      <td>[GO:0000785, GO:0004842, GO:0051865, GO:000627...</td>\n      <td>[C, F, P, P, P, F, F]</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"protein_function_grouped_df = protein_function_grouped_df.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:13.448209Z","iopub.execute_input":"2025-12-07T23:05:13.448932Z","iopub.status.idle":"2025-12-07T23:05:13.496874Z","shell.execute_reply.started":"2025-12-07T23:05:13.448903Z","shell.execute_reply":"2025-12-07T23:05:13.496268Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"protein_function_grouped_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:13.816391Z","iopub.execute_input":"2025-12-07T23:05:13.817047Z","iopub.status.idle":"2025-12-07T23:05:13.832375Z","shell.execute_reply.started":"2025-12-07T23:05:13.817019Z","shell.execute_reply":"2025-12-07T23:05:13.831780Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"  EntryID                                       output_terms           aspect  \\\n0  P04268               [GO:0005515, GO:0005886, GO:0008092]        [F, C, F]   \n1  Q8LAP6  [GO:0005634, GO:0009507, GO:0009534, GO:000953...  [C, C, C, C, C]   \n2  Q03489                                       [GO:0005515]              [F]   \n3  Q96PQ6                           [GO:0005515, GO:0005634]           [F, C]   \n4  Q59RK9  [GO:0008233, GO:0005739, GO:0042775, GO:004401...  [F, C, P, P, P]   \n\n      emb_0     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n0  0.828323  0.703457  1.160203 -0.054023 -0.939162 -1.085810  1.780389   \n1 -0.793946 -0.121416  0.264455 -0.091416  0.171004  0.079607  0.149902   \n2 -0.825974  0.277098 -0.046827 -0.155165 -0.192515 -0.353548  0.237032   \n3  1.056239  1.366326 -0.094833 -0.112145 -0.218979  0.265883  0.452629   \n4 -0.249164 -0.473922  0.326476 -0.376346 -0.044497 -0.192280 -0.052922   \n\n      emb_7     emb_8     emb_9    emb_10    emb_11    emb_12    emb_13  \\\n0  0.795923  0.361770  0.317409 -0.095173 -0.350046 -0.512594 -0.313681   \n1 -0.034930 -0.256049  0.294488  0.015121 -0.285039 -0.168807  0.164656   \n2  0.520949  0.298848 -0.230937 -0.166167  0.181591 -0.110926 -0.025534   \n3  0.542162  0.305502  0.255235 -0.147662  0.492993  0.423559 -0.004679   \n4 -0.022000 -0.123031 -0.181675  0.263037  0.056715 -0.134725  0.348870   \n\n     emb_14    emb_15  taxonomyID  \n0  0.097373  0.833666        9031  \n1 -0.089438 -0.239670        3702  \n2  0.032579 -0.221545        4102  \n3 -0.289698  0.479508        9606  \n4  0.097481 -0.156761      237561  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>output_terms</th>\n      <th>aspect</th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>emb_10</th>\n      <th>emb_11</th>\n      <th>emb_12</th>\n      <th>emb_13</th>\n      <th>emb_14</th>\n      <th>emb_15</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P04268</td>\n      <td>[GO:0005515, GO:0005886, GO:0008092]</td>\n      <td>[F, C, F]</td>\n      <td>0.828323</td>\n      <td>0.703457</td>\n      <td>1.160203</td>\n      <td>-0.054023</td>\n      <td>-0.939162</td>\n      <td>-1.085810</td>\n      <td>1.780389</td>\n      <td>0.795923</td>\n      <td>0.361770</td>\n      <td>0.317409</td>\n      <td>-0.095173</td>\n      <td>-0.350046</td>\n      <td>-0.512594</td>\n      <td>-0.313681</td>\n      <td>0.097373</td>\n      <td>0.833666</td>\n      <td>9031</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q8LAP6</td>\n      <td>[GO:0005634, GO:0009507, GO:0009534, GO:000953...</td>\n      <td>[C, C, C, C, C]</td>\n      <td>-0.793946</td>\n      <td>-0.121416</td>\n      <td>0.264455</td>\n      <td>-0.091416</td>\n      <td>0.171004</td>\n      <td>0.079607</td>\n      <td>0.149902</td>\n      <td>-0.034930</td>\n      <td>-0.256049</td>\n      <td>0.294488</td>\n      <td>0.015121</td>\n      <td>-0.285039</td>\n      <td>-0.168807</td>\n      <td>0.164656</td>\n      <td>-0.089438</td>\n      <td>-0.239670</td>\n      <td>3702</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q03489</td>\n      <td>[GO:0005515]</td>\n      <td>[F]</td>\n      <td>-0.825974</td>\n      <td>0.277098</td>\n      <td>-0.046827</td>\n      <td>-0.155165</td>\n      <td>-0.192515</td>\n      <td>-0.353548</td>\n      <td>0.237032</td>\n      <td>0.520949</td>\n      <td>0.298848</td>\n      <td>-0.230937</td>\n      <td>-0.166167</td>\n      <td>0.181591</td>\n      <td>-0.110926</td>\n      <td>-0.025534</td>\n      <td>0.032579</td>\n      <td>-0.221545</td>\n      <td>4102</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q96PQ6</td>\n      <td>[GO:0005515, GO:0005634]</td>\n      <td>[F, C]</td>\n      <td>1.056239</td>\n      <td>1.366326</td>\n      <td>-0.094833</td>\n      <td>-0.112145</td>\n      <td>-0.218979</td>\n      <td>0.265883</td>\n      <td>0.452629</td>\n      <td>0.542162</td>\n      <td>0.305502</td>\n      <td>0.255235</td>\n      <td>-0.147662</td>\n      <td>0.492993</td>\n      <td>0.423559</td>\n      <td>-0.004679</td>\n      <td>-0.289698</td>\n      <td>0.479508</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q59RK9</td>\n      <td>[GO:0008233, GO:0005739, GO:0042775, GO:004401...</td>\n      <td>[F, C, P, P, P]</td>\n      <td>-0.249164</td>\n      <td>-0.473922</td>\n      <td>0.326476</td>\n      <td>-0.376346</td>\n      <td>-0.044497</td>\n      <td>-0.192280</td>\n      <td>-0.052922</td>\n      <td>-0.022000</td>\n      <td>-0.123031</td>\n      <td>-0.181675</td>\n      <td>0.263037</td>\n      <td>0.056715</td>\n      <td>-0.134725</td>\n      <td>0.348870</td>\n      <td>0.097481</td>\n      <td>-0.156761</td>\n      <td>237561</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"protein_function_grouped_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:23:56.470428Z","iopub.execute_input":"2025-12-07T23:23:56.471375Z","iopub.status.idle":"2025-12-07T23:23:56.476773Z","shell.execute_reply.started":"2025-12-07T23:23:56.471341Z","shell.execute_reply":"2025-12-07T23:23:56.475896Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"Index(['EntryID', 'output_terms', 'aspect', 'emb_0', 'emb_1', 'emb_2', 'emb_3',\n       'emb_4', 'emb_5', 'emb_6', 'emb_7', 'emb_8', 'emb_9', 'emb_10',\n       'emb_11', 'emb_12', 'emb_13', 'emb_14', 'emb_15', 'taxonomyID'],\n      dtype='object')"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Columns for Training and Columns for Testing\nPREDICTORS = [f\"emb_{i}\" for i in range(PCA_TARGET_DIM)]\nPREDICTORS.append(\"EntryID\")\nOUTPUTS = ['output_terms']\n\nX, y = protein_function_grouped_df[PREDICTORS].values, protein_function_grouped_df[OUTPUTS].iloc[:, 0].tolist()\n\nX_train_all, X_test, y_train_all, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n# Perform a second split for validation set for finetuning our model\nX_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.1, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:52:29.780353Z","iopub.execute_input":"2025-12-08T01:52:29.780617Z","iopub.status.idle":"2025-12-08T01:52:30.061637Z","shell.execute_reply.started":"2025-12-08T01:52:29.780598Z","shell.execute_reply":"2025-12-08T01:52:30.061065Z"}},"outputs":[],"execution_count":207},{"cell_type":"code","source":"X_train_entry_ids = [data_row[-1] for data_row in X_train]\nX_val_entry_ids = [data_row[-1] for data_row in X_val]\nX_test_entry_ids = [data_row[-1] for data_row in X_test]\nX_train = np.array([data_row[:-1] for data_row in X_train])\nX_val = np.array([data_row[:-1] for data_row in X_val])\nX_test = np.array([data_row[:-1] for data_row in X_test])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:52:30.337808Z","iopub.execute_input":"2025-12-08T01:52:30.338095Z","iopub.status.idle":"2025-12-08T01:52:30.496507Z","shell.execute_reply.started":"2025-12-08T01:52:30.338071Z","shell.execute_reply":"2025-12-08T01:52:30.495688Z"}},"outputs":[],"execution_count":208},{"cell_type":"code","source":"y_train[:3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:52:35.046748Z","iopub.execute_input":"2025-12-08T01:52:35.047314Z","iopub.status.idle":"2025-12-08T01:52:35.051967Z","shell.execute_reply.started":"2025-12-08T01:52:35.047288Z","shell.execute_reply":"2025-12-08T01:52:35.051289Z"}},"outputs":[{"execution_count":209,"output_type":"execute_result","data":{"text/plain":"[['GO:0030514',\n  'GO:0045668',\n  'GO:0005886',\n  'GO:0005515',\n  'GO:0005737',\n  'GO:0016477',\n  'GO:0030512',\n  'GO:0045893',\n  'GO:0090263',\n  'GO:0005114',\n  'GO:0010718',\n  'GO:0008284',\n  'GO:0008360',\n  'GO:0005109'],\n ['GO:0005829'],\n ['GO:0005829',\n  'GO:0005515',\n  'GO:1905821',\n  'GO:0000796',\n  'GO:0007076',\n  'GO:0016020']]"},"metadata":{}}],"execution_count":209},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\nterm_to_index = {term: i for i, term in enumerate(UNIQUE_TERMS)}\n\nmlb = MultiLabelBinarizer(classes=UNIQUE_TERMS)\ny_train_transformed = mlb.fit_transform(y_train)\ny_val_transformed = mlb.transform(y_val)\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"constant\", fill_value=0)\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\nX_val_imputed = imputer.transform(X_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:52:38.297388Z","iopub.execute_input":"2025-12-08T01:52:38.298083Z","iopub.status.idle":"2025-12-08T01:52:39.543403Z","shell.execute_reply.started":"2025-12-08T01:52:38.298056Z","shell.execute_reply":"2025-12-08T01:52:39.542568Z"}},"outputs":[],"execution_count":210},{"cell_type":"code","source":"import xgboost as xgb\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\n\nnum_models = 100\n\nmodels_dict = {}\ndef train_xgb_models():\n    models = []\n    for i in range(num_models):\n        print(f\"\\nTraining model for label {i}...\")\n    \n        y_i = y_train_transformed[:, i]\n    \n        pos = np.sum(y_i == 1)\n        neg = np.sum(y_i == 0)\n        scale_pos_weight = neg / pos if pos > 0 else 1.0\n    \n        print(f\"Label {i} imbalance pos={pos}, neg={neg}, scaling weight={scale_pos_weight}\")\n    \n        dtrain = xgb.DMatrix(X_train_imputed, label=y_i)\n    \n        params = {\n            \"objective\": \"binary:logistic\",\n            \"eval_metric\": \"aucpr\",\n            \"tree_method\": \"hist\",\n            \"max_depth\": 7,\n            \"eta\": 0.05,\n            \"lambda\": 1.5,\n            \"alpha\": 0.8,\n            \"min_child_weight\": 2,\n            \"subsample\": 0.8,\n            \"colsample_bytree\": 0.8,\n            \"scale_pos_weight\": scale_pos_weight\n        }\n    \n        model = xgb.train(\n            params=params,\n            dtrain=dtrain,\n            num_boost_round=300,\n            evals=[(dtrain, \"train\")],\n            early_stopping_rounds=25,\n            verbose_eval=50\n        )\n    \n        models.append(model)\n    return models\n\ndef train_logistic_regression_models(i):\n\n    print(f\"\\nTraining model for label {i}...\")\n    \n    y_i = y_train_transformed[:, i]\n    # Sample not good\n    if len(np.unique(y_i)) < 2:\n        models_dict[f\"lr_{i}\"] = None\n        return\n\n    pos = np.sum(y_i == 1)\n    neg = np.sum(y_i == 0)\n    scale_pos_weight = neg / pos if pos > 0 else 1.0\n    \n    print(f\"Label {i}\")\n    \n    model = LogisticRegression(\n        penalty=\"l2\",\n        solver=\"liblinear\",\n        class_weight={0: 1.0, 1: scale_pos_weight},\n        max_iter=200,\n    )\n    \n    model.fit(X_train_imputed, y_i)\n    models_dict[f\"lr_{i}\"] = model\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T00:07:14.105955Z","iopub.execute_input":"2025-12-08T00:07:14.106627Z","iopub.status.idle":"2025-12-08T00:07:14.114128Z","shell.execute_reply.started":"2025-12-08T00:07:14.106601Z","shell.execute_reply":"2025-12-08T00:07:14.113360Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"dval = xgb.DMatrix(X_val)\n\n\nxgb_pred_list = []\nfor model in xgboost_models:\n    print(f\"model: {model}\")\n    xgb_pred_list.append(model.predict(dval))\n\nxgb_preds = np.column_stack(xgb_pred_list)\n\nlr_pred_list = []\nfor model in logistic_regression_models:\n    print(f\"model: {model}\")\n    lr_pred_list.append(model.predict(X_val_imputed))\n\nlr_preds = np.column_stack(lr_pred_list)\n\nmodel_predictions_dict = {\n    \"xgb_preds\": xgb_preds,\n    \"lr_preds\": lr_preds\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:46:42.212672Z","iopub.execute_input":"2025-12-07T23:46:42.212977Z","iopub.status.idle":"2025-12-07T23:46:42.705286Z","shell.execute_reply.started":"2025-12-07T23:46:42.212954Z","shell.execute_reply":"2025-12-07T23:46:42.704652Z"}},"outputs":[{"name":"stdout","text":"model: <xgboost.core.Booster object at 0x7f5b9a954b90>\nmodel: <xgboost.core.Booster object at 0x7f5b972cc550>\nmodel: <xgboost.core.Booster object at 0x7f5b9a9cd910>\nmodel: <xgboost.core.Booster object at 0x7f5b971b6610>\nmodel: <xgboost.core.Booster object at 0x7f5bbae9b710>\nmodel: <xgboost.core.Booster object at 0x7f5b972cf790>\nmodel: <xgboost.core.Booster object at 0x7f5b9a948850>\nmodel: <xgboost.core.Booster object at 0x7f5b981adf90>\nmodel: <xgboost.core.Booster object at 0x7f5b974a0dd0>\nmodel: <xgboost.core.Booster object at 0x7f5bbac25e10>\nmodel: <xgboost.core.Booster object at 0x7f5bb9d09450>\nmodel: <xgboost.core.Booster object at 0x7f5bec32dfd0>\nmodel: <xgboost.core.Booster object at 0x7f5b972cf9d0>\nmodel: <xgboost.core.Booster object at 0x7f5b972d7610>\nmodel: <xgboost.core.Booster object at 0x7f5b972cc510>\nmodel: <xgboost.core.Booster object at 0x7f5b9a9cd790>\nmodel: <xgboost.core.Booster object at 0x7f5bec34bb10>\nmodel: <xgboost.core.Booster object at 0x7f5b98cc1990>\nmodel: <xgboost.core.Booster object at 0x7f5b9749d890>\nmodel: <xgboost.core.Booster object at 0x7f5bb9d09050>\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 87.0675}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 182.95300261096605}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 781.8222222222222}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1676.4761904761904}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 977.5277777777778}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 106.56335877862595}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1.4516824999130042}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 938.3866666666667}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 38.8045197740113}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 3707.1052631578946}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1082.9076923076923}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 14089.8}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 213.7987804878049}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2428.448275862069}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2708.769230769231}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7827.222222222223}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2817.16}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 8805.75}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2817.16}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1082.9076923076923}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 22.08453473132372}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 5031.428571428572}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 3913.1111111111113}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7044.4}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7044.4}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 381.9021739130435}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1257.107142857143}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 902.2564102564103}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 596.0677966101695}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1099.84375}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 319.24545454545455}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 902.2564102564103}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1257.107142857143}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7.114950472241419}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 8805.75}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7827.222222222223}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 14089.8}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 5.330667625123551}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 837.7380952380952}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1082.9076923076923}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 520.8814814814815}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 11741.333333333334}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1257.107142857143}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 24.480650994575043}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7.683017007641114}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1853.0526315789473}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 245.34265734265733}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 143.66940451745378}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 622.4867256637168}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 27.96957236842105}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1235.0350877192982}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7044.4}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 15.361820715281004}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 5.208494888967219}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2708.769230769231}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 21.97163351809586}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1066.4848484848485}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 323.6728110599078}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 3521.7}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 3913.1111111111113}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 70453.0}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2708.769230769231}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 4143.35294117647}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1193.135593220339}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1303.7037037037037}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1436.8367346938776}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 102.76141384388806}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1600.2272727272727}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 55.45352564102564}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 77.10864745011087}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 683.0194174757281}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 281.9477911646586}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 740.6210526315789}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 23483.666666666668}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1676.4761904761904}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 447.7515923566879}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 297.53389830508473}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 406.2485549132948}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 13.328655684360383}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 70453.0}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 35226.0}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 11741.333333333334}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 14089.8}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1135.3548387096773}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1380.450980392157}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 453.541935483871}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1805.5128205128206}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 3521.7}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 11741.333333333334}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7827.222222222223}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 14089.8}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 225.54019292604502}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1853.0526315789473}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 764.804347826087}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1005.4857142857143}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1530.608695652174}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2515.214285714286}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 199.72364672364674}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 134.48846153846154}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 596.0677966101695}, max_iter=200,\n                   solver='liblinear')\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\nfor k, v in model_predictions_dict.items():\n    pred_binary = (v >= 0.5).astype(int)\n    \n    y_true = y_val_transformed[:, :num_models]\n    \n    accuracy_per_label = []\n    f1_per_label = []\n\n    for i in range(len(pred_binary[0])):\n        acc = accuracy_score(y_true[:, i], pred_binary[:, i])\n        f1  = f1_score(y_true[:, i], pred_binary[:, i], zero_division=0)\n    \n        accuracy_per_label.append(acc)\n        f1_per_label.append(f1)\n    \n        print(f\"Model: {k} Label {i}:  Accuracy = {acc:.4f},   F1 = {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:50:58.232798Z","iopub.execute_input":"2025-12-07T23:50:58.233595Z","iopub.status.idle":"2025-12-07T23:50:58.945805Z","shell.execute_reply.started":"2025-12-07T23:50:58.233565Z","shell.execute_reply":"2025-12-07T23:50:58.945141Z"}},"outputs":[{"name":"stdout","text":"Model: xgb_preds Label 0:  Accuracy = 0.9599,   F1 = 0.0977\nModel: xgb_preds Label 1:  Accuracy = 0.9894,   F1 = 0.3025\nModel: xgb_preds Label 2:  Accuracy = 0.9954,   F1 = 0.0000\nModel: xgb_preds Label 3:  Accuracy = 0.9986,   F1 = 0.0000\nModel: xgb_preds Label 4:  Accuracy = 0.9987,   F1 = 0.1667\nModel: xgb_preds Label 5:  Accuracy = 0.9670,   F1 = 0.1400\nModel: xgb_preds Label 6:  Accuracy = 0.6647,   F1 = 0.6331\nModel: xgb_preds Label 7:  Accuracy = 0.9981,   F1 = 0.1176\nModel: xgb_preds Label 8:  Accuracy = 0.9157,   F1 = 0.1771\nModel: xgb_preds Label 9:  Accuracy = 0.9991,   F1 = 0.4615\nModel: xgb_preds Label 10:  Accuracy = 0.9990,   F1 = 0.6000\nModel: xgb_preds Label 11:  Accuracy = 1.0000,   F1 = 0.0000\nModel: xgb_preds Label 12:  Accuracy = 0.9891,   F1 = 0.2478\nModel: xgb_preds Label 13:  Accuracy = 0.9997,   F1 = 0.5000\nModel: xgb_preds Label 14:  Accuracy = 0.9940,   F1 = 0.0784\nModel: xgb_preds Label 15:  Accuracy = 0.9997,   F1 = 0.0000\nModel: xgb_preds Label 16:  Accuracy = 0.9953,   F1 = 0.1395\nModel: xgb_preds Label 17:  Accuracy = 0.9997,   F1 = 0.0000\nModel: xgb_preds Label 18:  Accuracy = 0.9980,   F1 = 0.0000\nModel: xgb_preds Label 19:  Accuracy = 0.9626,   F1 = 0.0579\nModel: lr_preds Label 0:  Accuracy = 0.6851,   F1 = 0.0595\nModel: lr_preds Label 1:  Accuracy = 0.6765,   F1 = 0.0239\nModel: lr_preds Label 2:  Accuracy = 0.7328,   F1 = 0.0038\nModel: lr_preds Label 3:  Accuracy = 0.7093,   F1 = 0.0044\nModel: lr_preds Label 4:  Accuracy = 0.6822,   F1 = 0.0024\nModel: lr_preds Label 5:  Accuracy = 0.7370,   F1 = 0.0525\nModel: lr_preds Label 6:  Accuracy = 0.6480,   F1 = 0.6063\nModel: lr_preds Label 7:  Accuracy = 0.7545,   F1 = 0.0031\nModel: lr_preds Label 8:  Accuracy = 0.6051,   F1 = 0.0630\nModel: lr_preds Label 9:  Accuracy = 0.9862,   F1 = 0.0690\nModel: lr_preds Label 10:  Accuracy = 0.8184,   F1 = 0.0111\nModel: lr_preds Label 11:  Accuracy = 0.9963,   F1 = 0.0000\nModel: lr_preds Label 12:  Accuracy = 0.7803,   F1 = 0.0326\nModel: lr_preds Label 13:  Accuracy = 0.8889,   F1 = 0.0023\nModel: lr_preds Label 14:  Accuracy = 0.8449,   F1 = 0.0049\nModel: lr_preds Label 15:  Accuracy = 0.9400,   F1 = 0.0000\nModel: lr_preds Label 16:  Accuracy = 0.8958,   F1 = 0.0097\nModel: lr_preds Label 17:  Accuracy = 0.9941,   F1 = 0.0417\nModel: lr_preds Label 18:  Accuracy = 0.8227,   F1 = 0.0000\nModel: lr_preds Label 19:  Accuracy = 0.8361,   F1 = 0.0153\nModel: lr_preds Label 20:  Accuracy = 0.6715,   F1 = 0.1409\nModel: lr_preds Label 21:  Accuracy = 0.8659,   F1 = 0.0000\nModel: lr_preds Label 22:  Accuracy = 0.8573,   F1 = 0.0036\nModel: lr_preds Label 23:  Accuracy = 0.9160,   F1 = 0.0060\nModel: lr_preds Label 24:  Accuracy = 0.9239,   F1 = 0.0100\nModel: lr_preds Label 25:  Accuracy = 0.6724,   F1 = 0.0085\nModel: lr_preds Label 26:  Accuracy = 0.7951,   F1 = 0.0050\nModel: lr_preds Label 27:  Accuracy = 0.9092,   F1 = 0.0327\nModel: lr_preds Label 28:  Accuracy = 0.6992,   F1 = 0.0117\nModel: lr_preds Label 29:  Accuracy = 0.6950,   F1 = 0.0050\nModel: lr_preds Label 30:  Accuracy = 0.6643,   F1 = 0.0113\nModel: lr_preds Label 31:  Accuracy = 0.7083,   F1 = 0.0035\nModel: lr_preds Label 32:  Accuracy = 0.8610,   F1 = 0.0073\nModel: lr_preds Label 33:  Accuracy = 0.7380,   F1 = 0.3843\nModel: lr_preds Label 34:  Accuracy = 0.9281,   F1 = 0.0035\nModel: lr_preds Label 35:  Accuracy = 0.8803,   F1 = 0.0021\nModel: lr_preds Label 36:  Accuracy = 0.9324,   F1 = 0.0000\nModel: lr_preds Label 37:  Accuracy = 0.5805,   F1 = 0.3633\nModel: lr_preds Label 38:  Accuracy = 0.7691,   F1 = 0.0055\nModel: lr_preds Label 39:  Accuracy = 0.8165,   F1 = 0.0042\nModel: lr_preds Label 40:  Accuracy = 0.7803,   F1 = 0.0194\nModel: lr_preds Label 41:  Accuracy = 0.9624,   F1 = 0.0000\nModel: lr_preds Label 42:  Accuracy = 0.7545,   F1 = 0.0083\nModel: lr_preds Label 43:  Accuracy = 0.7932,   F1 = 0.2316\nModel: lr_preds Label 44:  Accuracy = 0.5552,   F1 = 0.2703\nModel: lr_preds Label 45:  Accuracy = 0.8728,   F1 = 0.0060\nModel: lr_preds Label 46:  Accuracy = 0.7251,   F1 = 0.0209\nModel: lr_preds Label 47:  Accuracy = 0.6160,   F1 = 0.0240\nModel: lr_preds Label 48:  Accuracy = 0.6901,   F1 = 0.0082\nModel: lr_preds Label 49:  Accuracy = 0.6880,   F1 = 0.1222\nModel: lr_preds Label 50:  Accuracy = 0.7411,   F1 = 0.0078\nModel: lr_preds Label 51:  Accuracy = 0.9799,   F1 = 0.0000\nModel: lr_preds Label 52:  Accuracy = 0.7057,   F1 = 0.2366\nModel: lr_preds Label 53:  Accuracy = 0.6728,   F1 = 0.4352\nModel: lr_preds Label 54:  Accuracy = 0.7932,   F1 = 0.0000\nModel: lr_preds Label 55:  Accuracy = 0.6090,   F1 = 0.1068\nModel: lr_preds Label 56:  Accuracy = 0.6158,   F1 = 0.0046\nModel: lr_preds Label 57:  Accuracy = 0.6394,   F1 = 0.0070\nModel: lr_preds Label 58:  Accuracy = 0.8612,   F1 = 0.0037\nModel: lr_preds Label 59:  Accuracy = 0.7632,   F1 = 0.0022\nModel: lr_preds Label 60:  Accuracy = 0.9911,   F1 = 0.0000\nModel: lr_preds Label 61:  Accuracy = 0.8650,   F1 = 0.0038\nModel: lr_preds Label 62:  Accuracy = 0.8922,   F1 = 0.0024\nModel: lr_preds Label 63:  Accuracy = 0.7646,   F1 = 0.0086\nModel: lr_preds Label 64:  Accuracy = 0.7060,   F1 = 0.0026\nModel: lr_preds Label 65:  Accuracy = 0.6274,   F1 = 0.0027\nModel: lr_preds Label 66:  Accuracy = 0.6883,   F1 = 0.0446\nModel: lr_preds Label 67:  Accuracy = 0.7562,   F1 = 0.0042\nModel: lr_preds Label 68:  Accuracy = 0.7896,   F1 = 0.1497\nModel: lr_preds Label 69:  Accuracy = 0.7129,   F1 = 0.0711\nModel: lr_preds Label 70:  Accuracy = 0.7434,   F1 = 0.0108\nModel: lr_preds Label 71:  Accuracy = 0.6934,   F1 = 0.0083\nModel: lr_preds Label 72:  Accuracy = 0.7291,   F1 = 0.0056\nModel: lr_preds Label 73:  Accuracy = 0.9729,   F1 = 0.0000\nModel: lr_preds Label 74:  Accuracy = 0.8004,   F1 = 0.0026\nModel: lr_preds Label 75:  Accuracy = 0.8258,   F1 = 0.0326\nModel: lr_preds Label 76:  Accuracy = 0.8276,   F1 = 0.0439\nModel: lr_preds Label 77:  Accuracy = 0.8626,   F1 = 0.0393\nModel: lr_preds Label 78:  Accuracy = 0.6601,   F1 = 0.2399\nModel: lr_preds Label 79:  Accuracy = 0.9918,   F1 = 0.0000\nModel: lr_preds Label 80:  Accuracy = 0.9863,   F1 = 0.0000\nModel: lr_preds Label 81:  Accuracy = 0.8857,   F1 = 0.0000\nModel: lr_preds Label 82:  Accuracy = 0.9253,   F1 = 0.0000\nModel: lr_preds Label 83:  Accuracy = 0.7521,   F1 = 0.0031\nModel: lr_preds Label 84:  Accuracy = 0.7717,   F1 = 0.0045\nModel: lr_preds Label 85:  Accuracy = 0.6683,   F1 = 0.0092\nModel: lr_preds Label 86:  Accuracy = 0.7550,   F1 = 0.0042\nModel: lr_preds Label 87:  Accuracy = 0.7900,   F1 = 0.0012\nModel: lr_preds Label 88:  Accuracy = 0.9977,   F1 = 0.0000\nModel: lr_preds Label 89:  Accuracy = 0.8466,   F1 = 0.0017\nModel: lr_preds Label 90:  Accuracy = 0.9475,   F1 = 0.0000\nModel: lr_preds Label 91:  Accuracy = 0.6964,   F1 = 0.0222\nModel: lr_preds Label 92:  Accuracy = 0.7000,   F1 = 0.0025\nModel: lr_preds Label 93:  Accuracy = 0.8271,   F1 = 0.0102\nModel: lr_preds Label 94:  Accuracy = 0.7559,   F1 = 0.0031\nModel: lr_preds Label 95:  Accuracy = 0.8161,   F1 = 0.0069\nModel: lr_preds Label 96:  Accuracy = 0.8331,   F1 = 0.0015\nModel: lr_preds Label 97:  Accuracy = 0.7158,   F1 = 0.0168\nModel: lr_preds Label 98:  Accuracy = 0.8746,   F1 = 0.0874\nModel: lr_preds Label 99:  Accuracy = 0.8719,   F1 = 0.0157\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"from joblib import Parallel, delayed\nimport psutil\nn_cores = psutil.cpu_count()\nprint(f\"Available cores: {n_cores}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T00:04:32.279034Z","iopub.execute_input":"2025-12-08T00:04:32.279509Z","iopub.status.idle":"2025-12-08T00:04:32.283694Z","shell.execute_reply.started":"2025-12-08T00:04:32.279486Z","shell.execute_reply":"2025-12-08T00:04:32.282952Z"}},"outputs":[{"name":"stdout","text":"Available cores: 4\n","output_type":"stream"}],"execution_count":102},{"cell_type":"code","source":"results = Parallel(n_jobs=n_cores, verbose=10)(\n    delayed(train_logistic_regression_models)(i) for i in range(200)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T00:07:18.012093Z","iopub.execute_input":"2025-12-08T00:07:18.012362Z","iopub.status.idle":"2025-12-08T00:08:11.392425Z","shell.execute_reply.started":"2025-12-08T00:07:18.012341Z","shell.execute_reply":"2025-12-08T00:08:11.391555Z"}},"outputs":[{"name":"stderr","text":"[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:   10.5s\n[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   11.5s\n[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:   12.8s\n[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   14.7s\n[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   16.5s\n[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   18.7s\n[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   20.9s\n[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   23.3s\n[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   25.8s\n[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   29.0s\n[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   32.1s\n[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   35.3s\n[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed:   39.5s\n[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   42.9s\n[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed:   46.8s\n[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   51.0s\n[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   52.4s finished\n","output_type":"stream"}],"execution_count":111},{"cell_type":"code","source":"# b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T00:28:49.754066Z","iopub.execute_input":"2025-12-08T00:28:49.754357Z","iopub.status.idle":"2025-12-08T00:28:49.757715Z","shell.execute_reply.started":"2025-12-08T00:28:49.754334Z","shell.execute_reply":"2025-12-08T00:28:49.757173Z"}},"outputs":[],"execution_count":113},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\n\noutput_dim = 200\n\nclass WeightedMultiLabelNN(nn.Module):\n    def __init__(self, input_dim=16, output_dim=output_dim, hidden_dims=[64, 128, 256], pos_weights=None):\n        super().__init__()\n        self.pos_weights = pos_weights\n        layers = []\n        prev_dim = input_dim\n        for hidden_dim in hidden_dims:\n            layers.append(nn.Linear(prev_dim, hidden_dim))\n            layers.append(nn.BatchNorm1d(hidden_dim))\n            layers.append(nn.ReLU())\n            layers.append(nn.Dropout(0.1))\n            prev_dim = hidden_dim\n        self.features = nn.Sequential(*layers)\n        self.classifier = nn.Linear(prev_dim, output_dim)\n    \n    def forward(self, x):\n        features = self.features(x)\n        logits = self.classifier(features)\n        return logits\n\n\nclass PositionalWeightedLoss(nn.Module):\n    def __init__(self, pos_weights=None, label_weights=None, reduction='mean'):\n        super().__init__()\n        self.pos_weights = pos_weights\n        self.label_weights = label_weights\n        self.reduction = reduction\n        \n    def forward(self, logits, targets):\n        loss = F.binary_cross_entropy_with_logits(\n            logits,\n            targets,\n            reduction='none'\n        )\n        \n        if self.pos_weights is not None:\n            pos_mask = (targets > 0.5).float()\n            pos_weight_factor = 1 + (self.pos_weights.unsqueeze(0) - 1) * pos_mask\n            loss = loss * pos_weight_factor\n            \n        if self.label_weights is not None:\n            loss = loss * self.label_weights.unsqueeze(0)\n        \n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:\n            return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T00:37:25.176397Z","iopub.execute_input":"2025-12-08T00:37:25.176686Z","iopub.status.idle":"2025-12-08T00:37:25.185067Z","shell.execute_reply.started":"2025-12-08T00:37:25.176664Z","shell.execute_reply":"2025-12-08T00:37:25.184341Z"}},"outputs":[],"execution_count":114},{"cell_type":"code","source":"class ProteinEmbeddingsDataset(Dataset):\n    def __init__(self, features, labels, total_labels=output_dim, label_metadata=None):\n        self.features = features.astype(np.float32)\n        self.labels = labels[:, :total_labels].astype(np.float32)\n        self.label_metadata = label_metadata\n        \n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        x = torch.FloatTensor(self.features[idx])\n        y = torch.FloatTensor(self.labels[idx])\n        return x, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:14:36.978495Z","iopub.execute_input":"2025-12-08T01:14:36.979095Z","iopub.status.idle":"2025-12-08T01:14:36.983831Z","shell.execute_reply.started":"2025-12-08T01:14:36.979069Z","shell.execute_reply":"2025-12-08T01:14:36.983055Z"}},"outputs":[],"execution_count":136},{"cell_type":"code","source":"protein_embeddings_dataset_train = ProteinEmbeddingsDataset(X_train_imputed, y_train_transformed, total_labels=output_dim)\nprotein_embeddings_dataset_val = ProteinEmbeddingsDataset(X_val_imputed, y_val_transformed, total_labels=output_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:28:43.353349Z","iopub.execute_input":"2025-12-08T01:28:43.353626Z","iopub.status.idle":"2025-12-08T01:28:43.404352Z","shell.execute_reply.started":"2025-12-08T01:28:43.353603Z","shell.execute_reply":"2025-12-08T01:28:43.403782Z"}},"outputs":[],"execution_count":158},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef evaluate_f1(model, val_loader, device, threshold=0.5):\n    model.eval()\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        for features, targets in val_loader:\n            features = features.to(device)\n            targets = targets.to(device)\n\n            logits = model(features)\n            probs = torch.sigmoid(logits)\n\n            preds = (probs > threshold).float()\n\n            all_preds.append(preds.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n\n    all_preds = np.concatenate(all_preds, axis=0)\n    all_targets = np.concatenate(all_targets, axis=0)\n\n    num_labels = all_targets.shape[1]\n    f1_scores = []\n\n    for i in range(num_labels):\n        try:\n            f1 = f1_score(all_targets[:, i], all_preds[:, i], zero_division=0   )\n        except ValueError:\n            f1 = 0.0 \n        f1_scores.append(f1)\n\n    f1_scores = np.array(f1_scores)\n    best_idx = np.argsort(f1_scores)[-3:]\n    worst_idx = np.argsort(f1_scores)[:3]\n\n    return f1_scores, best_idx, worst_idx\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:32:30.953162Z","iopub.execute_input":"2025-12-08T01:32:30.953712Z","iopub.status.idle":"2025-12-08T01:32:30.959993Z","shell.execute_reply.started":"2025-12-08T01:32:30.953691Z","shell.execute_reply":"2025-12-08T01:32:30.959184Z"}},"outputs":[],"execution_count":167},{"cell_type":"code","source":"def obtain_label_metadata(curr_y):\n    label_metadata = {\n    \"pos_weights\": []\n    }\n    print(len(curr_y[0]))\n    for i in range(len(curr_y[0])):\n        if not i % 1000: print(i)\n        y_i = curr_y[:, i]\n        pos = np.sum(y_i == 1)\n        neg = np.sum(y_i == 0)\n        scale_pos_weight = neg / pos if pos > 0 else 1.0\n        label_metadata[\"pos_weights\"].append(scale_pos_weight)\n    return label_metadata\n\n\ndef train_model(model, train_loader, pos_weights, num_epochs=50):\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = model.to(device)\n    pos_weights = pos_weights.to(device)\n    \n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n    \n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0\n        \n        for features, targets in train_loader:\n            features = features.to(device)\n            targets = targets.to(device)\n            \n            logits = model(features)\n            loss = F.binary_cross_entropy_with_logits(\n                logits,\n                targets,\n                pos_weight=pos_weights,\n                reduction='mean'\n            )\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n        \n        print(f\"current eppoch {epoch+1}/{num_epochs} current loss: {total_loss/len(train_loader):.4f}\")\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:32:34.273656Z","iopub.execute_input":"2025-12-08T01:32:34.273959Z","iopub.status.idle":"2025-12-08T01:32:34.281006Z","shell.execute_reply.started":"2025-12-08T01:32:34.273937Z","shell.execute_reply":"2025-12-08T01:32:34.280246Z"}},"outputs":[],"execution_count":168},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\ndef train_model(model, train_loader, val_loader, pos_weights, num_epochs=50):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    pos_weights = pos_weights.to(device)\n\n    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n    for epoch in range(num_epochs):\n        model.train()\n        total_loss = 0.0\n\n        for features, targets in train_loader:\n            features = features.to(device)\n            targets = targets.to(device)\n\n            logits = model(features)\n\n            loss = F.binary_cross_entropy_with_logits(\n                logits,\n                targets,\n                pos_weight=pos_weights,\n                reduction=\"mean\"\n            )\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loader)\n        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}\")\n\n        # --- VALIDATION ---\n        f1_scores, best_idx, worst_idx = evaluate_f1(model, val_loader, device)\n\n        print(\"Top 3 labels (best F1):\")\n        for idx in reversed(best_idx):\n            print(f\"  Label {idx}: F1 = {f1_scores[idx]:.4f}\")\n\n        print(\"Bottom 3 labels (worst F1):\")\n        for idx in worst_idx:\n            print(f\"  Label {idx}: F1 = {f1_scores[idx]:.4f}\")\n\n        print(f\"Average f1 score: {np.mean(f1_scores)}\")\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:33:03.927258Z","iopub.execute_input":"2025-12-08T01:33:03.927946Z","iopub.status.idle":"2025-12-08T01:33:03.934886Z","shell.execute_reply.started":"2025-12-08T01:33:03.927918Z","shell.execute_reply":"2025-12-08T01:33:03.934110Z"}},"outputs":[],"execution_count":172},{"cell_type":"code","source":"label_metadata = obtain_label_metadata(y_train_transformed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T00:49:34.095651Z","iopub.execute_input":"2025-12-08T00:49:34.096024Z","iopub.status.idle":"2025-12-08T00:50:45.304154Z","shell.execute_reply.started":"2025-12-08T00:49:34.095994Z","shell.execute_reply":"2025-12-08T00:50:45.303535Z"}},"outputs":[{"name":"stdout","text":"26125\n0\n1000\n2000\n3000\n4000\n5000\n6000\n7000\n8000\n9000\n10000\n11000\n12000\n13000\n14000\n15000\n16000\n17000\n18000\n19000\n20000\n21000\n22000\n23000\n24000\n25000\n26000\n","output_type":"stream"}],"execution_count":126},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\ncurr_model = WeightedMultiLabelNN()\ndata_loader = DataLoader(protein_embeddings_dataset_train, batch_size=32)\ndata_loader_val = DataLoader(protein_embeddings_dataset_val)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:33:06.561082Z","iopub.execute_input":"2025-12-08T01:33:06.561583Z","iopub.status.idle":"2025-12-08T01:33:06.569603Z","shell.execute_reply.started":"2025-12-08T01:33:06.561558Z","shell.execute_reply":"2025-12-08T01:33:06.569024Z"}},"outputs":[],"execution_count":173},{"cell_type":"code","source":"trained_model_nn = train_model(curr_model, data_loader, data_loader_val, torch.tensor(label_metadata[\"pos_weights\"][:output_dim]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T01:33:07.100509Z","iopub.execute_input":"2025-12-08T01:33:07.100769Z","iopub.status.idle":"2025-12-08T01:43:46.983158Z","shell.execute_reply.started":"2025-12-08T01:33:07.100750Z","shell.execute_reply":"2025-12-08T01:43:46.982403Z"}},"outputs":[{"name":"stdout","text":"[Epoch 1/50] Loss: 2.0301\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6066\n  Label 53: F1 = 0.3716\n  Label 37: F1 = 0.3145\nBottom 3 labels (worst F1):\n  Label 194: F1 = 0.0000\n  Label 179: F1 = 0.0000\n  Label 109: F1 = 0.0000\nAverage f1 score: 0.02036426189012476\n[Epoch 2/50] Loss: 1.4014\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6068\n  Label 53: F1 = 0.3652\n  Label 37: F1 = 0.3132\nBottom 3 labels (worst F1):\n  Label 17: F1 = 0.0000\n  Label 80: F1 = 0.0000\n  Label 81: F1 = 0.0000\nAverage f1 score: 0.01969134649147814\n[Epoch 3/50] Loss: 1.2975\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6132\n  Label 53: F1 = 0.3634\n  Label 37: F1 = 0.3266\nBottom 3 labels (worst F1):\n  Label 194: F1 = 0.0000\n  Label 17: F1 = 0.0000\n  Label 114: F1 = 0.0000\nAverage f1 score: 0.020471092338956373\n[Epoch 4/50] Loss: 1.2272\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6038\n  Label 53: F1 = 0.3725\n  Label 37: F1 = 0.3223\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.02162932830718331\n[Epoch 5/50] Loss: 1.2020\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6108\n  Label 53: F1 = 0.3779\n  Label 37: F1 = 0.3315\nBottom 3 labels (worst F1):\n  Label 81: F1 = 0.0000\n  Label 82: F1 = 0.0000\n  Label 17: F1 = 0.0000\nAverage f1 score: 0.02273278715872811\n[Epoch 6/50] Loss: 1.1494\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6104\n  Label 53: F1 = 0.3908\n  Label 37: F1 = 0.3443\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.023315615268476676\n[Epoch 7/50] Loss: 1.0819\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6227\n  Label 53: F1 = 0.3963\n  Label 37: F1 = 0.3345\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 21: F1 = 0.0000\nAverage f1 score: 0.023597300658596256\n[Epoch 8/50] Loss: 1.0343\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6233\n  Label 53: F1 = 0.3952\n  Label 37: F1 = 0.3478\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.02475777773568219\n[Epoch 9/50] Loss: 1.0249\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6201\n  Label 53: F1 = 0.4049\n  Label 37: F1 = 0.3539\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 182: F1 = 0.0000\n  Label 21: F1 = 0.0000\nAverage f1 score: 0.025212299598586143\n[Epoch 10/50] Loss: 0.9892\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6167\n  Label 53: F1 = 0.3984\n  Label 37: F1 = 0.3493\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 182: F1 = 0.0000\n  Label 122: F1 = 0.0000\nAverage f1 score: 0.024856208374459392\n[Epoch 11/50] Loss: 1.0171\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6196\n  Label 53: F1 = 0.3972\n  Label 37: F1 = 0.3527\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 21: F1 = 0.0000\nAverage f1 score: 0.025155512033973936\n[Epoch 12/50] Loss: 0.9650\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6186\n  Label 53: F1 = 0.4037\n  Label 33: F1 = 0.3604\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 182: F1 = 0.0000\n  Label 168: F1 = 0.0000\nAverage f1 score: 0.025658740723865398\n[Epoch 13/50] Loss: 0.9307\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6198\n  Label 53: F1 = 0.4108\n  Label 37: F1 = 0.3477\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.025390958767298796\n[Epoch 14/50] Loss: 0.8858\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6158\n  Label 53: F1 = 0.4063\n  Label 37: F1 = 0.3630\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 182: F1 = 0.0000\n  Label 122: F1 = 0.0000\nAverage f1 score: 0.02572588873229426\n[Epoch 15/50] Loss: 0.8724\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6229\n  Label 53: F1 = 0.4088\n  Label 37: F1 = 0.3618\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.025935583078781112\n[Epoch 16/50] Loss: 0.8610\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6230\n  Label 53: F1 = 0.4125\n  Label 37: F1 = 0.3655\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.026352939108743166\n[Epoch 17/50] Loss: 0.8803\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6220\n  Label 53: F1 = 0.4163\n  Label 37: F1 = 0.3609\nBottom 3 labels (worst F1):\n  Label 60: F1 = 0.0000\n  Label 130: F1 = 0.0000\n  Label 136: F1 = 0.0000\nAverage f1 score: 0.025986694412187674\n[Epoch 18/50] Loss: 0.8689\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6239\n  Label 53: F1 = 0.4085\n  Label 37: F1 = 0.3587\nBottom 3 labels (worst F1):\n  Label 179: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.025382338212392875\n[Epoch 19/50] Loss: 0.8505\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6212\n  Label 53: F1 = 0.4085\n  Label 37: F1 = 0.3607\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.02556118942273857\n[Epoch 20/50] Loss: 0.8264\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6247\n  Label 53: F1 = 0.4002\n  Label 37: F1 = 0.3661\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 168: F1 = 0.0000\n  Label 79: F1 = 0.0000\nAverage f1 score: 0.02570782216098442\n[Epoch 21/50] Loss: 0.8343\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6248\n  Label 53: F1 = 0.4136\n  Label 37: F1 = 0.3625\nBottom 3 labels (worst F1):\n  Label 80: F1 = 0.0000\n  Label 81: F1 = 0.0000\n  Label 11: F1 = 0.0000\nAverage f1 score: 0.026065927735512168\n[Epoch 22/50] Loss: 0.8547\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6221\n  Label 53: F1 = 0.4081\n  Label 33: F1 = 0.3624\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.025997314567226423\n[Epoch 23/50] Loss: 0.8028\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6236\n  Label 53: F1 = 0.4038\n  Label 37: F1 = 0.3625\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 168: F1 = 0.0000\nAverage f1 score: 0.02586663828652116\n[Epoch 24/50] Loss: 0.8244\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6246\n  Label 53: F1 = 0.4058\n  Label 37: F1 = 0.3646\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.026010203658437564\n[Epoch 25/50] Loss: 0.7975\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6258\n  Label 53: F1 = 0.4126\n  Label 37: F1 = 0.3671\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 168: F1 = 0.0000\n  Label 114: F1 = 0.0000\nAverage f1 score: 0.02615379678492813\n[Epoch 26/50] Loss: 0.7807\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6222\n  Label 53: F1 = 0.4129\n  Label 33: F1 = 0.3640\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.02657064903708019\n[Epoch 27/50] Loss: 0.7924\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6211\n  Label 53: F1 = 0.4048\n  Label 37: F1 = 0.3656\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 15: F1 = 0.0000\nAverage f1 score: 0.02585620695885968\n[Epoch 28/50] Loss: 0.7896\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6253\n  Label 53: F1 = 0.4078\n  Label 37: F1 = 0.3698\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.02641403998414412\n[Epoch 29/50] Loss: 0.7905\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6218\n  Label 53: F1 = 0.4099\n  Label 37: F1 = 0.3656\nBottom 3 labels (worst F1):\n  Label 150: F1 = 0.0000\n  Label 136: F1 = 0.0000\n  Label 194: F1 = 0.0000\nAverage f1 score: 0.026372851239865377\n[Epoch 30/50] Loss: 0.7805\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6242\n  Label 53: F1 = 0.4124\n  Label 33: F1 = 0.3716\nBottom 3 labels (worst F1):\n  Label 179: F1 = 0.0000\n  Label 135: F1 = 0.0000\n  Label 73: F1 = 0.0000\nAverage f1 score: 0.026385604379096116\n[Epoch 31/50] Loss: 0.7672\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6221\n  Label 53: F1 = 0.4069\n  Label 33: F1 = 0.3688\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 15: F1 = 0.0000\nAverage f1 score: 0.02622963728958422\n[Epoch 32/50] Loss: 0.7665\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6264\n  Label 53: F1 = 0.4166\n  Label 37: F1 = 0.3684\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.02597581273748814\n[Epoch 33/50] Loss: 0.7665\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6191\n  Label 53: F1 = 0.4137\n  Label 33: F1 = 0.3749\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.02669765125810169\n[Epoch 34/50] Loss: 0.7499\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6181\n  Label 53: F1 = 0.4204\n  Label 37: F1 = 0.3698\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 15: F1 = 0.0000\nAverage f1 score: 0.026589130881656195\n[Epoch 35/50] Loss: 0.7829\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6227\n  Label 53: F1 = 0.4162\n  Label 37: F1 = 0.3754\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.026336535957755026\n[Epoch 36/50] Loss: 0.7419\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6275\n  Label 53: F1 = 0.4183\n  Label 37: F1 = 0.3644\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.026411424702040297\n[Epoch 37/50] Loss: 0.7278\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6235\n  Label 53: F1 = 0.4111\n  Label 33: F1 = 0.3685\nBottom 3 labels (worst F1):\n  Label 21: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 168: F1 = 0.0000\nAverage f1 score: 0.026691701849230993\n[Epoch 38/50] Loss: 0.7379\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6266\n  Label 53: F1 = 0.4171\n  Label 37: F1 = 0.3664\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 182: F1 = 0.0000\n  Label 21: F1 = 0.0000\nAverage f1 score: 0.026755580703766445\n[Epoch 39/50] Loss: 0.7301\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6253\n  Label 53: F1 = 0.4226\n  Label 33: F1 = 0.3698\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 114: F1 = 0.0000\nAverage f1 score: 0.026779890652470394\n[Epoch 40/50] Loss: 0.7369\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6197\n  Label 53: F1 = 0.4213\n  Label 37: F1 = 0.3668\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.026535006597625053\n[Epoch 41/50] Loss: 0.7260\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6246\n  Label 53: F1 = 0.4173\n  Label 33: F1 = 0.3726\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 182: F1 = 0.0000\n  Label 21: F1 = 0.0000\nAverage f1 score: 0.027243036072682303\n[Epoch 42/50] Loss: 0.7304\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6245\n  Label 53: F1 = 0.4155\n  Label 33: F1 = 0.3736\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 182: F1 = 0.0000\n  Label 21: F1 = 0.0000\nAverage f1 score: 0.026786166592229356\n[Epoch 43/50] Loss: 0.7369\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6176\n  Label 53: F1 = 0.4151\n  Label 33: F1 = 0.3771\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 15: F1 = 0.0000\nAverage f1 score: 0.026800541431996044\n[Epoch 44/50] Loss: 0.7332\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6265\n  Label 53: F1 = 0.4167\n  Label 37: F1 = 0.3725\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.02628493424506057\n[Epoch 45/50] Loss: 0.7304\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6217\n  Label 53: F1 = 0.4107\n  Label 33: F1 = 0.3733\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 15: F1 = 0.0000\nAverage f1 score: 0.026518693559453688\n[Epoch 46/50] Loss: 0.7117\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6246\n  Label 53: F1 = 0.4170\n  Label 33: F1 = 0.3756\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 15: F1 = 0.0000\nAverage f1 score: 0.026852762128904032\n[Epoch 47/50] Loss: 0.7268\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6268\n  Label 53: F1 = 0.4111\n  Label 37: F1 = 0.3721\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 122: F1 = 0.0000\n  Label 130: F1 = 0.0000\nAverage f1 score: 0.02697083033430297\n[Epoch 48/50] Loss: 0.7501\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6300\n  Label 53: F1 = 0.4073\n  Label 33: F1 = 0.3802\nBottom 3 labels (worst F1):\n  Label 179: F1 = 0.0000\n  Label 180: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.02623713718557703\n[Epoch 49/50] Loss: 0.7486\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6259\n  Label 53: F1 = 0.4117\n  Label 33: F1 = 0.3700\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 15: F1 = 0.0000\nAverage f1 score: 0.026371485321438987\n[Epoch 50/50] Loss: 0.7167\nTop 3 labels (best F1):\n  Label 6: F1 = 0.6273\n  Label 53: F1 = 0.4127\n  Label 37: F1 = 0.3722\nBottom 3 labels (worst F1):\n  Label 11: F1 = 0.0000\n  Label 194: F1 = 0.0000\n  Label 182: F1 = 0.0000\nAverage f1 score: 0.026852821531766286\n","output_type":"stream"}],"execution_count":174},{"cell_type":"code","source":"subontology_GCNs, subontology_graph_dfs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T00:10:45.896039Z","iopub.execute_input":"2025-12-08T00:10:45.896788Z","iopub.status.idle":"2025-12-08T00:10:45.911975Z","shell.execute_reply.started":"2025-12-08T00:10:45.896760Z","shell.execute_reply":"2025-12-08T00:10:45.911362Z"}},"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"({'biological_process': SimpleGCN(\n    (conv1): GCNConv(16, 32)\n    (conv2): GCNConv(32, 16)\n  ),\n  'molecular_function': SimpleGCN(\n    (conv1): GCNConv(16, 32)\n    (conv2): GCNConv(32, 16)\n  ),\n  'cellular_component': SimpleGCN(\n    (conv1): GCNConv(16, 32)\n    (conv2): GCNConv(32, 16)\n  )},\n {'biological_process':              term      parent relation                              name  \\\n  0      GO:0000001  GO:0048308     is_a         mitochondrion inheritance   \n  1      GO:0000001  GO:0048311     is_a         mitochondrion inheritance   \n  2      GO:0000002  GO:0007005     is_a  mitochondrial genome maintenance   \n  7      GO:0000011  GO:0007033     is_a               vacuole inheritance   \n  8      GO:0000011  GO:0048308     is_a               vacuole inheritance   \n  ...           ...         ...      ...                               ...   \n  62403  GO:2001316  GO:0120254     is_a      kojic acid metabolic process   \n  62404  GO:2001317  GO:0034309     is_a   kojic acid biosynthetic process   \n  62405  GO:2001317  GO:0042181     is_a   kojic acid biosynthetic process   \n  62406  GO:2001317  GO:0120255     is_a   kojic acid biosynthetic process   \n  62407  GO:2001317  GO:2001316     is_a   kojic acid biosynthetic process   \n  \n                  namespace                                                def  \\\n  0      biological_process  \"The distribution of mitochondria, including t...   \n  1      biological_process  \"The distribution of mitochondria, including t...   \n  2      biological_process  \"The maintenance of the structure and integrit...   \n  7      biological_process  \"The distribution of vacuoles into daughter ce...   \n  8      biological_process  \"The distribution of vacuoles into daughter ce...   \n  ...                   ...                                                ...   \n  62403  biological_process  \"The chemical reactions and pathways involving...   \n  62404  biological_process  \"The chemical reactions and pathways resulting...   \n  62405  biological_process  \"The chemical reactions and pathways resulting...   \n  62406  biological_process  \"The chemical reactions and pathways resulting...   \n  62407  biological_process  \"The chemical reactions and pathways resulting...   \n  \n                                                   synonym  \n  0                 [\"mitochondrial inheritance\" EXACT []]  \n  1                 [\"mitochondrial inheritance\" EXACT []]  \n  2                                                     []  \n  7                                                     []  \n  8                                                     []  \n  ...                                                  ...  \n  62403  [\"5-hydroxy-2-(hydroxymethyl)-4H-pyran-4-one m...  \n  62404  [\"5-hydroxy-2-(hydroxymethyl)-4H-pyran-4-one a...  \n  62405  [\"5-hydroxy-2-(hydroxymethyl)-4H-pyran-4-one a...  \n  62406  [\"5-hydroxy-2-(hydroxymethyl)-4H-pyran-4-one a...  \n  62407  [\"5-hydroxy-2-(hydroxymethyl)-4H-pyran-4-one a...  \n  \n  [45220 rows x 7 columns],\n  'molecular_function':              term      parent relation  \\\n  3      GO:0000006  GO:0005385     is_a   \n  4      GO:0000007  GO:0005385     is_a   \n  5      GO:0000009  GO:0000030     is_a   \n  6      GO:0000010  GO:0120531     is_a   \n  10     GO:0000014  GO:0004520     is_a   \n  ...           ...         ...      ...   \n  62005  GO:2001085  GO:0030247     is_a   \n  62095  GO:2001147  GO:1901681     is_a   \n  62227  GO:2001227  GO:0043168     is_a   \n  62228  GO:2001227  GO:0097243     is_a   \n  62229  GO:2001227  GO:0097367     is_a   \n  \n                                                      name           namespace  \\\n  3      high-affinity zinc transmembrane transporter a...  molecular_function   \n  4      low-affinity zinc ion transmembrane transporte...  molecular_function   \n  5                 alpha-1,6-mannosyltransferase activity  molecular_function   \n  6              heptaprenyl diphosphate synthase activity  molecular_function   \n  10     single-stranded DNA endodeoxyribonuclease acti...  molecular_function   \n  ...                                                  ...                 ...   \n  62005                            arabinogalactan binding  molecular_function   \n  62095                                  camalexin binding  molecular_function   \n  62227                                 quercitrin binding  molecular_function   \n  62228                                 quercitrin binding  molecular_function   \n  62229                                 quercitrin binding  molecular_function   \n  \n                                                       def  \\\n  3      \"Enables the transfer of zinc ions (Zn2+) from...   \n  4      \"Enables the transfer of a solute or solutes f...   \n  5      \"Catalysis of the transfer of a mannose residu...   \n  6      \"Catalysis of the reaction: (2E,6E)-farnesyl d...   \n  10     \"Catalysis of the hydrolysis of ester linkages...   \n  ...                                                  ...   \n  62005  \"Binding to arabinogalactan.\" [GOC:mengo_curat...   \n  62095                 \"Binding to camalexin.\" [GOC:obol]   \n  62227                \"Binding to quercitrin.\" [GOC:obol]   \n  62228                \"Binding to quercitrin.\" [GOC:obol]   \n  62229                \"Binding to quercitrin.\" [GOC:obol]   \n  \n                                                   synonym  \n  3      [\"high affinity zinc uptake transmembrane tran...  \n  4                                                     []  \n  5      [\"1,6-alpha-mannosyltransferase activity\" EXAC...  \n  6      [\"all-trans-heptaprenyl-diphosphate synthase a...  \n  10     [\"single-stranded DNA specific endodeoxyribonu...  \n  ...                                                  ...  \n  62005                                                 []  \n  62095  [\"3-(1,3-thiazol-2-yl)-1H-indole binding\" EXAC...  \n  62227                                                 []  \n  62228                                                 []  \n  62229                                                 []  \n  \n  [12561 rows x 7 columns],\n  'cellular_component':              term      parent relation  \\\n  12     GO:0000015  GO:1902494     is_a   \n  114    GO:0000109  GO:0140513     is_a   \n  115    GO:0000110  GO:0000109     is_a   \n  116    GO:0000111  GO:0000109     is_a   \n  117    GO:0000112  GO:0000109     is_a   \n  ...           ...         ...      ...   \n  60086  GO:1990971  GO:0098637     is_a   \n  60087  GO:1990972  GO:0098637     is_a   \n  60088  GO:1990973  GO:0043232     is_a   \n  62408  GO:7770001  GO:0098800     is_a   \n  62409  GO:7770001  GO:1902495     is_a   \n  \n                                                name           namespace  \\\n  12               phosphopyruvate hydratase complex  cellular_component   \n  114             nucleotide-excision repair complex  cellular_component   \n  115    nucleotide-excision repair factor 1 complex  cellular_component   \n  116    nucleotide-excision repair factor 2 complex  cellular_component   \n  117    nucleotide-excision repair factor 3 complex  cellular_component   \n  ...                                            ...                 ...   \n  60086                               EMILIN complex  cellular_component   \n  60087                           multimerin complex  cellular_component   \n  60088    transmembrane actin-associated (TAN) line  cellular_component   \n  62408       mitochondrial pyruvate carrier complex  cellular_component   \n  62409       mitochondrial pyruvate carrier complex  cellular_component   \n  \n                                                       def  \\\n  12     \"A multimeric enzyme complex, usually a dimer ...   \n  114    \"Any complex formed of proteins that act in nu...   \n  115    \"One of several protein complexes involved in ...   \n  116    \"One of several protein complexes involved in ...   \n  117    \"One of several protein complexes involved in ...   \n  ...                                                  ...   \n  60086  \"Glycoprotein complex of the C1q/TNF superfami...   \n  60087  \"Glycoprotein complex of the C1q/TNF superfami...   \n  60088  \"A linear array of nuclear envelope membrane p...   \n  62408  \"An inner mitochondrial protein carrier capabl...   \n  62409  \"An inner mitochondrial protein carrier capabl...   \n  \n                                                   synonym  \n  12                          [\"enolase complex\" EXACT []]  \n  114    [\"UvrB-UvrC complex\" NARROW [PMID:12145219], \"...  \n  115    [\"NEF1 complex\" EXACT [], \"XPA-ERCC1-ERCC4 com...  \n  116                            [\"NEF2 complex\" EXACT []]  \n  117                            [\"NEF3 complex\" EXACT []]  \n  ...                                                  ...  \n  60086  [\"Elastic microfibrillar interface 1 complex\" ...  \n  60087  [\"Elastic microfibrillar interface 3 complex\" ...  \n  60088                            [\"TAN line\" RELATED []]  \n  62408                                                 []  \n  62409                                                 []  \n  \n  [4629 rows x 7 columns]})"},"metadata":{}},{"name":"stdout","text":"\nTraining model for label 3...\nLabel 3\n\nTraining model for label 6...\nLabel 6\n\nTraining model for label 8...\nLabel 8\n\nTraining model for label 12...\nLabel 12\n\nTraining model for label 16...\nLabel 16\n\nTraining model for label 19...\nLabel 19\n\nTraining model for label 21...\nLabel 21\n\nTraining model for label 26...\nLabel 26\n\nTraining model for label 30...\nLabel 30\n\nTraining model for label 34...\nLabel 34\n\nTraining model for label 38...\nLabel 38\n\nTraining model for label 42...\nLabel 42\n\nTraining model for label 47...\nLabel 47\n\nTraining model for label 51...\nLabel 51\n\nTraining model for label 56...\nLabel 56\n\nTraining model for label 60...\nLabel 60\n\nTraining model for label 64...\nLabel 64\n\nTraining model for label 68...\nLabel 68\n\nTraining model for label 73...\nLabel 73\n\nTraining model for label 77...\nLabel 77\n\nTraining model for label 81...\nLabel 81\n\nTraining model for label 85...\nLabel 85\n\nTraining model for label 89...\nLabel 89\n\nTraining model for label 93...\nLabel 93\n\nTraining model for label 97...\nLabel 97\n\nTraining model for label 101...\nLabel 101\n\nTraining model for label 106...\nLabel 106\n\nTraining model for label 110...\nLabel 110\n\nTraining model for label 114...\nLabel 114\n\nTraining model for label 118...\nLabel 118\n\nTraining model for label 122...\nLabel 122\n\nTraining model for label 127...\nLabel 127\n\nTraining model for label 131...\nLabel 131\n\nTraining model for label 135...\nLabel 135\n\nTraining model for label 139...\nLabel 139\n\nTraining model for label 143...\nLabel 143\n\nTraining model for label 147...\n\nTraining model for label 148...\nLabel 148\n\nTraining model for label 152...\nLabel 152\n\nTraining model for label 156...\nLabel 156\n\nTraining model for label 160...\nLabel 160\n\nTraining model for label 164...\nLabel 164\n\nTraining model for label 168...\nLabel 168\n\nTraining model for label 172...\nLabel 172\n\nTraining model for label 176...\nLabel 176\n\nTraining model for label 180...\nLabel 180\n\nTraining model for label 184...\nLabel 184\n\nTraining model for label 188...\nLabel 188\n\nTraining model for label 191...\nLabel 191\n\nTraining model for label 195...\nLabel 195\n\nTraining model for label 0...\nLabel 0\n\nTraining model for label 7...\nLabel 7\n\nTraining model for label 11...\nLabel 11\n\nTraining model for label 15...\nLabel 15\n\nTraining model for label 20...\nLabel 20\n\nTraining model for label 23...\nLabel 23\n\nTraining model for label 28...\nLabel 28\n\nTraining model for label 32...\nLabel 32\n\nTraining model for label 36...\nLabel 36\n\nTraining model for label 41...\nLabel 41\n\nTraining model for label 45...\nLabel 45\n\nTraining model for label 50...\nLabel 50\n\nTraining model for label 54...\nLabel 54\n\nTraining model for label 59...\nLabel 59\n\nTraining model for label 62...\nLabel 62\n\nTraining model for label 67...\nLabel 67\n\nTraining model for label 71...\nLabel 71\n\nTraining model for label 75...\nLabel 75\n\nTraining model for label 79...\nLabel 79\n\nTraining model for label 83...\nLabel 83\n\nTraining model for label 87...\nLabel 87\n\nTraining model for label 91...\nLabel 91\n\nTraining model for label 95...\nLabel 95\n\nTraining model for label 99...\nLabel 99\n\nTraining model for label 104...\nLabel 104\n\nTraining model for label 108...\nLabel 108\n\nTraining model for label 112...\nLabel 112\n\nTraining model for label 116...\nLabel 116\n\nTraining model for label 120...\nLabel 120\n\nTraining model for label 124...\nLabel 124\n\nTraining model for label 128...\nLabel 128\n\nTraining model for label 132...\nLabel 132\n\nTraining model for label 136...\nLabel 136\n\nTraining model for label 141...\nLabel 141\n\nTraining model for label 144...\nLabel 144\n\nTraining model for label 149...\nLabel 149\n\nTraining model for label 153...\nLabel 153\n\nTraining model for label 158...\nLabel 158\n\nTraining model for label 162...\nLabel 162\n\nTraining model for label 166...\nLabel 166\n\nTraining model for label 171...\nLabel 171\n\nTraining model for label 174...\nLabel 174\n\nTraining model for label 177...\nLabel 177\n\nTraining model for label 183...\nLabel 183\n\nTraining model for label 187...\nLabel 187\n\nTraining model for label 193...\nLabel 193\n\nTraining model for label 197...\nLabel 197\n\nTraining model for label 2...\nLabel 2\n\nTraining model for label 5...\nLabel 5\n\nTraining model for label 9...\nLabel 9\n\nTraining model for label 14...\nLabel 14\n\nTraining model for label 18...\nLabel 18\n\nTraining model for label 24...\nLabel 24\n\nTraining model for label 27...\nLabel 27\n\nTraining model for label 31...\nLabel 31\n\nTraining model for label 35...\nLabel 35\n\nTraining model for label 39...\nLabel 39\n\nTraining model for label 43...\nLabel 43\n\nTraining model for label 46...\nLabel 46\n\nTraining model for label 49...\nLabel 49\n\nTraining model for label 53...\nLabel 53\n\nTraining model for label 57...\nLabel 57\n\nTraining model for label 61...\nLabel 61\n\nTraining model for label 65...\nLabel 65\n\nTraining model for label 69...\nLabel 69\n\nTraining model for label 72...\nLabel 72\n\nTraining model for label 76...\nLabel 76\n\nTraining model for label 80...\nLabel 80\n\nTraining model for label 84...\nLabel 84\n\nTraining model for label 88...\nLabel 88\n\nTraining model for label 92...\nLabel 92\n\nTraining model for label 96...\nLabel 96\n\nTraining model for label 100...\nLabel 100\n\nTraining model for label 103...\nLabel 103\n\nTraining model for label 107...\nLabel 107\n\nTraining model for label 111...\nLabel 111\n\nTraining model for label 115...\nLabel 115\n\nTraining model for label 119...\nLabel 119\n\nTraining model for label 123...\nLabel 123\n\nTraining model for label 126...\nLabel 126\n\nTraining model for label 130...\nLabel 130\n\nTraining model for label 134...\nLabel 134\n\nTraining model for label 138...\nLabel 138\n\nTraining model for label 140...\nLabel 140\n\nTraining model for label 145...\nLabel 145\n\nTraining model for label 150...\nLabel 150\n\nTraining model for label 154...\nLabel 154\n\nTraining model for label 159...\nLabel 159\n\nTraining model for label 163...\nLabel 163\n\nTraining model for label 165...\nLabel 165\n\nTraining model for label 169...\nLabel 169\n\nTraining model for label 175...\nLabel 175\n\nTraining model for label 179...\nLabel 179\n\nTraining model for label 182...\nLabel 182\n\nTraining model for label 186...\nLabel 186\n\nTraining model for label 190...\nLabel 190\n\nTraining model for label 194...\nLabel 194\n\nTraining model for label 198...\nLabel 198\n\nTraining model for label 1...\nLabel 1\n\nTraining model for label 4...\nLabel 4\n\nTraining model for label 10...\nLabel 10\n\nTraining model for label 13...\nLabel 13\n\nTraining model for label 17...\nLabel 17\n\nTraining model for label 22...\nLabel 22\n\nTraining model for label 25...\nLabel 25\n\nTraining model for label 29...\nLabel 29\n\nTraining model for label 33...\nLabel 33\n\nTraining model for label 37...\nLabel 37\n\nTraining model for label 40...\nLabel 40\n\nTraining model for label 44...\nLabel 44\n\nTraining model for label 48...\nLabel 48\n\nTraining model for label 52...\nLabel 52\n\nTraining model for label 55...\nLabel 55\n\nTraining model for label 58...\nLabel 58\n\nTraining model for label 63...\nLabel 63\n\nTraining model for label 66...\nLabel 66\n\nTraining model for label 70...\nLabel 70\n\nTraining model for label 74...\nLabel 74\n\nTraining model for label 78...\nLabel 78\n\nTraining model for label 82...\nLabel 82\n\nTraining model for label 86...\nLabel 86\n\nTraining model for label 90...\nLabel 90\n\nTraining model for label 94...\nLabel 94\n\nTraining model for label 98...\nLabel 98\n\nTraining model for label 102...\nLabel 102\n\nTraining model for label 105...\nLabel 105\n\nTraining model for label 109...\nLabel 109\n\nTraining model for label 113...\nLabel 113\n\nTraining model for label 117...\nLabel 117\n\nTraining model for label 121...\nLabel 121\n\nTraining model for label 125...\nLabel 125\n\nTraining model for label 129...\nLabel 129\n\nTraining model for label 133...\nLabel 133\n\nTraining model for label 137...\nLabel 137\n\nTraining model for label 142...\nLabel 142\n\nTraining model for label 146...\nLabel 146\n\nTraining model for label 151...\nLabel 151\n\nTraining model for label 155...\nLabel 155\n\nTraining model for label 157...\nLabel 157\n\nTraining model for label 161...\nLabel 161\n\nTraining model for label 167...\nLabel 167\n\nTraining model for label 170...\nLabel 170\n\nTraining model for label 173...\nLabel 173\n\nTraining model for label 178...\nLabel 178\n\nTraining model for label 181...\nLabel 181\n\nTraining model for label 185...\nLabel 185\n\nTraining model for label 189...\nLabel 189\n\nTraining model for label 192...\nLabel 192\n\nTraining model for label 196...\nLabel 196\n\nTraining model for label 199...\nLabel 199\n","output_type":"stream"}],"execution_count":112},{"cell_type":"code","source":"def create_go_embeddings_optimized(obo_path, go_terms, embed_dim=16, hidden_dim=32, out_dim=16, epochs=50):\n\n    print(\" Loading Gene Ontology...\")\n    graph = obonet.read_obo(obo_path)\n\n\n    edges = pd.DataFrame([\n        {'source': u, 'target': v, 'relation': data.get('relation', 'is_a')}\n        for u, v, data in graph.edges(data=True)\n    ])\n\n    relevant_edges = edges[\n        edges['source'].isin(go_terms) | edges['target'].isin(go_terms)\n    ].reset_index(drop=True)\n\n    nodes = pd.DataFrame({'id': list(set(relevant_edges['source']).union(relevant_edges['target']))})\n    nodes['node_idx'] = range(len(nodes))\n    node2idx = dict(zip(nodes['id'], nodes['node_idx']))\n\n    edge_index = torch.tensor([\n        [node2idx[s] for s in relevant_edges['source']],\n        [node2idx[t] for t in relevant_edges['target']]\n    ], dtype=torch.long)\n\n    num_nodes = len(nodes)\n    print(f\"Using {num_nodes} GO terms and {len(relevant_edges)} edges\")\n\n\n    x = torch.randn((num_nodes, embed_dim), dtype=torch.float32)\n\n\n    class SimpleGCN(nn.Module):\n        def __init__(self, in_dim, hidden_dim, out_dim):\n            super(SimpleGCN, self).__init__()\n            self.conv1 = GCNConv(in_dim, hidden_dim)\n            self.conv2 = GCNConv(hidden_dim, out_dim)\n\n        def forward(self, x, edge_index):\n            x = self.conv1(x, edge_index)\n            x = F.relu(x)\n            x = self.conv2(x, edge_index)\n            return x\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = SimpleGCN(embed_dim, hidden_dim, out_dim).to(device)\n\n\n    x = x.to(device)\n    edge_index = edge_index.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n    data = Data(x=x, edge_index=edge_index)\n\n    print(f\"Training on device: {device}\")\n    for epoch in range(epochs):\n        model.train()\n        optimizer.zero_grad()\n        embeddings = model(data.x, data.edge_index)\n        # Inner product decoder\n        recon = torch.sigmoid(torch.matmul(embeddings, embeddings.T))\n        adj_true = torch.zeros_like(recon)\n        adj_true[data.edge_index[0], data.edge_index[1]] = 1.0\n\n        loss = F.binary_cross_entropy(recon, adj_true)\n        loss.backward()\n        optimizer.step()\n\n        if epoch % 10 == 0 or epoch == epochs - 1:\n            print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f}\")\n\n\n    with torch.no_grad():\n        node_embeddings = model(data.x, data.edge_index).cpu().numpy()\n\n    del model, x, data, recon, adj_true\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    col_names = [f\"go_emb_{i}\" for i in range(node_embeddings.shape[1])]\n\n    emb_df = pd.DataFrame(node_embeddings, index=nodes['id'], columns=col_names)\n    print(f\"Created embeddings for {len(emb_df)} GO terms\")\n    return emb_df\n\n\n\n","metadata":{"id":"2m-aaVT0ZigK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sampled_data = sample_tsv(term_path, sample_frac=0.05)\ngo_terms = sampled_data['term'].unique()\nembeddings_df = create_go_embeddings_optimized(obo_path, go_terms)\nseq_df = extract_sequences(fasta_path, sampled_data['EntryID'])","metadata":{"id":"kL3g8zaoZ-0e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Combine GO embedding and PLM embedding into one dataset","metadata":{"id":"Rs5c-b4jjE_C"}},{"cell_type":"code","source":"def combine_go_protein_embeddings(sampled_data, go_emb_df, prot_emb_df):\n\n    combined = sampled_data.merge(go_emb_df, how='left', left_on='term', right_index=True)\n\n    combined = combined.merge(prot_emb_df, how='left', left_on='EntryID', right_index=True)\n\n    return combined\n\n\nmultimodal_df = combine_go_protein_embeddings(sampled_data, embeddings_df, prot_emb_df)\n\nprint(\"Multimodal feature dataframe shape:\", multimodal_df.shape)\nprint(multimodal_df.head())","metadata":{"id":"0mV_c_ALcisR","trusted":true},"outputs":[],"execution_count":null}]}