{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","name":"dataprocessing"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":116062,"databundleVersionId":14084779,"sourceType":"competition"},{"sourceId":14033853,"sourceType":"datasetVersion","datasetId":8936736}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==2.7.0\n!pip install torch-geometric\n!pip install biopython\n!pip install obonet\n!pip install networkx\n!pip install pandas\n!pip install numpy\n!pip install matplotlib\n!pip install seaborn\n!pip install scipy\n!pip install scikit-learn\n!pip install fair-esm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yg7HmzhSVM8L","outputId":"4c74257c-3122-4d26-da06-2e732cb1a6dd","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:55:57.389399Z","iopub.execute_input":"2025-12-07T22:55:57.389637Z","iopub.status.idle":"2025-12-07T22:59:17.900168Z","shell.execute_reply.started":"2025-12-07T22:55:57.389618Z","shell.execute_reply":"2025-12-07T22:59:17.899242Z"}},"outputs":[{"name":"stdout","text":"Collecting torch==2.7.0\n  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (4.15.0)\nCollecting sympy>=1.13.3 (from torch==2.7.0)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.0) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton==3.3.0 (from torch==2.7.0)\n  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch==2.7.0) (75.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.0) (3.0.3)\nDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.0 triton-3.3.0\nCollecting torch-geometric\n  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.13.2)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.10.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.1.3)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.6.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.22.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-geometric) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.10.5)\nRequirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-geometric) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-geometric) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-geometric) (2024.2.0)\nDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch-geometric\nSuccessfully installed torch-geometric-2.7.0\nCollecting biopython\n  Downloading biopython-1.86-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->biopython) (2024.2.0)\nDownloading biopython-1.86-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: biopython\nSuccessfully installed biopython-1.86\nCollecting obonet\n  Downloading obonet-1.1.1-py3-none-any.whl.metadata (6.7 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from obonet) (3.5)\nDownloading obonet-1.1.1-py3-none-any.whl (9.2 kB)\nInstalling collected packages: obonet\nSuccessfully installed obonet-1.1.1\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->matplotlib) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->matplotlib) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\nRequirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.3)\nRequirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.7.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy!=1.24.0,>=1.17->seaborn) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.25->seaborn) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy!=1.24.0,>=1.17->seaborn) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy!=1.24.0,>=1.17->seaborn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy!=1.24.0,>=1.17->seaborn) (2024.2.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\nRequirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.5,>=1.23.5->scipy) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.5,>=1.23.5->scipy) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.5,>=1.23.5->scipy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.5,>=1.23.5->scipy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.5,>=1.23.5->scipy) (2024.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nCollecting fair-esm\n  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\nDownloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fair-esm\nSuccessfully installed fair-esm-2.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\" # avoid fragmentation\nimport torch\nimport torch_geometric\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import GCNConv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport Bio\nfrom Bio import SeqIO\nimport obonet\nimport gc\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport random\nimport esm\n","metadata":{"id":"GGPDDs_kXqU9","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:17.901857Z","iopub.execute_input":"2025-12-07T22:59:17.902194Z","iopub.status.idle":"2025-12-07T22:59:26.077426Z","shell.execute_reply.started":"2025-12-07T22:59:17.902171Z","shell.execute_reply":"2025-12-07T22:59:26.076828Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"obo_path = '/kaggle/input/cafa-6-protein-function-prediction/Train/go-basic.obo'\nfasta_path = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_sequences.fasta'\nterm_path = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv'\ntaxonomy_path = '/kaggle/input/cafa-6-protein-function-prediction/Train/train_taxonomy.tsv'","metadata":{"id":"R7rUQCNdVug8","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.078167Z","iopub.execute_input":"2025-12-07T22:59:26.078592Z","iopub.status.idle":"2025-12-07T22:59:26.082927Z","shell.execute_reply.started":"2025-12-07T22:59:26.078564Z","shell.execute_reply":"2025-12-07T22:59:26.082114Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"LARGEST_FASTA_SEQ_LEN = 8922\nESM_EMBEDDING_DIM = 320\nPCA_TARGET_DIM = 16","metadata":{"id":"DGqwUSV6v0pF","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.083917Z","iopub.execute_input":"2025-12-07T22:59:26.084162Z","iopub.status.idle":"2025-12-07T22:59:26.099127Z","shell.execute_reply.started":"2025-12-07T22:59:26.084144Z","shell.execute_reply":"2025-12-07T22:59:26.098357Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"term_df = pd.read_csv(term_path, sep='\\t')\nterm_df.head(), len(term_df[\"term\"].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.100803Z","iopub.execute_input":"2025-12-07T22:59:26.101336Z","iopub.status.idle":"2025-12-07T22:59:26.450015Z","shell.execute_reply.started":"2025-12-07T22:59:26.101316Z","shell.execute_reply":"2025-12-07T22:59:26.449405Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"INQOe3ORgEhq","outputId":"06dffad4-67af-4570-ba3b-cbb65053105f"},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(  EntryID        term aspect\n 0  Q5W0B1  GO:0000785      C\n 1  Q5W0B1  GO:0004842      F\n 2  Q5W0B1  GO:0051865      P\n 3  Q5W0B1  GO:0006275      P\n 4  Q5W0B1  GO:0006513      P,\n 26125)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"taxonomy_df = pd.read_csv(taxonomy_path, sep='\\t', names=['EntryID', 'taxonomyID'])\ntaxonomy_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.450827Z","iopub.execute_input":"2025-12-07T22:59:26.451115Z","iopub.status.idle":"2025-12-07T22:59:26.504636Z","shell.execute_reply.started":"2025-12-07T22:59:26.451097Z","shell.execute_reply":"2025-12-07T22:59:26.504076Z"},"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ICSCnvj0gEhq","outputId":"15f82984-c0ff-4ea7-9385-8bd43a92e8bc"},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      EntryID  taxonomyID\n0  A0A0C5B5G6        9606\n1      A0JNW5        9606\n2      A0JP26        9606\n3      A0PK11        9606\n4      A1A4S6        9606","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A0C5B5G6</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0JNW5</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0JP26</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0PK11</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A1A4S6</td>\n      <td>9606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# def get_processed_fasta_df(fasta_data, term_df):\n#     fasta_dict_list = []\n#     term_set = set(term_df.tolist())\n#     for fasta_seq in fasta_data:\n#         entry = fasta_seq.id.split('|')[1] if '|' in fasta_seq.id else fasta_seq.id\n#         if entry in term_set:\n#             fasta_dict_list.append({\n#                 \"EntryID\": entry,\n#                 \"fasta_sequence\": str(fasta_seq.seq)\n#             })\n\n#     return pd.DataFrame(fasta_dict_list)\n\n\ndef sample_tsv(tsv_df, sample_frac=0.05, random_state=42):\n    \"\"\"\n    Read a TSV file and sample based on unique EntryID.\n    Pulls in all associated rows for sampled EntryIDs.\n    \"\"\"\n    df = tsv_df\n    unique_ids = df['EntryID'].unique()\n    sample_size = max(1, int(len(unique_ids) * sample_frac))\n    sampled_ids = random.sample(list(unique_ids), sample_size)\n    sampled_df = df[df['EntryID'].isin(sampled_ids)]\n    print(f\"Sampled {len(sampled_df)} rows from {len(unique_ids)} unique EntryIDs\")\n    return sampled_df\n\n\ndef get_processed_fasta_df(fasta_data):\n    fasta_dict_list = []\n    for fasta_seq in fasta_data:\n        entry = fasta_seq.id.split('|')[1] if '|' in fasta_seq.id else fasta_seq.id\n        fasta_dict_list.append({\n                \"EntryID\": entry,\n                \"fasta_sequence\": str(fasta_seq.seq)\n            })\n\n    return pd.DataFrame(fasta_dict_list)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.505394Z","iopub.execute_input":"2025-12-07T22:59:26.505621Z","iopub.status.idle":"2025-12-07T22:59:26.511519Z","shell.execute_reply.started":"2025-12-07T22:59:26.505604Z","shell.execute_reply":"2025-12-07T22:59:26.510779Z"},"id":"Cs-etgEDgEhq"},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Get Merged DF FULL (includes batching to fit embeddings into GPU and offloads to CPU)","metadata":{"id":"3hKLO3KwgEhr"}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\nmodel = model.to(device)\nmodel = model.half()\nmodel.eval()\nbatch_converter = alphabet.get_batch_converter()\n\ndef generate_protein_embeddings_esm_batch(seq_df, seq_col='Sequence', entryid_col='EntryID',\n                                              target_dim=16, batch_size=1, use_fp16=True):\n    \"\"\"\n    Memory-optimized ESM embedding generation for proteins.\n    Processes small batches and moves embeddings to CPU immediately.\n    \"\"\"\n    sequences = seq_df[seq_col].tolist()\n    entry_ids = seq_df[entryid_col].tolist()\n    print(f\"sequences: {len(sequences)} entry_ids {len(entry_ids)}\")\n\n    all_embeddings = []\n    # print(len(sequences))\n    dtype = torch.float16 if use_fp16 else torch.float32\n    for i in range(0, len(sequences), batch_size):\n        try:\n            batch_seqs = sequences[i:i+batch_size]\n            batch_labels = entry_ids[i:i+batch_size]\n            if len(batch_seqs[0]) > LARGEST_FASTA_SEQ_LEN:\n                print(f\"length of batch seqs is: {len(batch_seqs[0])}\")\n                # Split the sequence to be max length LARGEST_FASTA_SEQ_LEN (will always be len 1 batch), this helps avoid the loss of information\n                curr_seq = batch_seqs[0]\n                embeddings_list = []\n                for i in range(0, len( batch_seqs[0]), LARGEST_FASTA_SEQ_LEN):\n                  curr_seq = batch_seqs[0][i:i+LARGEST_FASTA_SEQ_LEN]\n                  curr_seq_embedding = get_sequence_embedding_esm(batch_labels, [curr_seq], dtype)\n                  embeddings_list.append(curr_seq_embedding)\n                # Average the embeddings_list since the long sequences were broken down into smaller chunks\n                seq_embeddings = np.mean(embeddings_list, axis=0)\n\n            else:\n              seq_embeddings = get_sequence_embedding_esm(batch_labels, batch_seqs, dtype)\n\n            all_embeddings.append(seq_embeddings)\n            del seq_embeddings\n        except Exception as e:\n            print(e)\n            print(len(batch_seqs[0]))\n            print(batch_seqs)\n\n\n    raw_embeddings = np.vstack(all_embeddings)\n    # Mitigate memory constraints\n    gc.collect()\n    torch.cuda.empty_cache()\n    torch.cuda.ipc_collect()\n    torch.cuda.reset_peak_memory_stats()\n\n    col_names = [f\"prot_emb_{i}\" for i in range(320)]\n    emb_df = pd.DataFrame(raw_embeddings, index=entry_ids, columns=col_names)\n    emb_df.index.name = entryid_col\n\n    return emb_df\n\n\ndef get_sequence_embedding_esm(batch_labels, batch_seqs, dtype):\n    batch_data = [(label, seq) for label, seq in zip(batch_labels, batch_seqs)]\n    _, _, batch_tokens = batch_converter(batch_data)\n    batch_tokens = batch_tokens.to(device)\n    with torch.no_grad():\n      with torch.autocast(device_type=\"cuda\", dtype=dtype):\n          results = model(batch_tokens, repr_layers=[model.num_layers], return_contacts=False)\n          token_embeddings = results[\"representations\"][model.num_layers]  # (B, L, D)\n          # Mean pool over sequence length\n          attention_mask = batch_tokens != alphabet.padding_idx\n          masked_embeddings = token_embeddings * attention_mask.unsqueeze(-1)\n          seq_lengths = attention_mask.sum(dim=1).unsqueeze(-1)\n          seq_embeddings = (masked_embeddings.sum(dim=1) / seq_lengths).cpu().float().numpy()\n          del batch_tokens, token_embeddings, masked_embeddings, results, attention_mask\n          return seq_embeddings\n\n\ndef apply_pca_to_esm_embeddings(esm_embeddings_df:pd.DataFrame, target_dim=16):\n    '''\n    Helper method \n    '''\n    emb_cols = [c for c in esm_embeddings_df.columns if c.startswith(\"prot_emb\")]\n    \n    tensor_list = [ \n        torch.tensor(row[emb_cols].values.astype(\"float16\"), dtype=torch.float16)\n        for _, row in esm_embeddings_df.iterrows()\n    ]\n    \n    pca = PCA(n_components=PCA_TARGET_DIM)\n    tensor_list_transformed = pca.fit_transform(tensor_list)\n    \n    # Intialize dictionary where we use EntryID for joining with all the other data\n    embeddings_dict = { \"EntryID\": [] }\n    # Initialize empty PCA embeddings for the pd.DataFrame\n    for i in range(PCA_TARGET_DIM):\n        embeddings_dict[f\"emb_{i}\"] =  []\n        \n    # Append EntryID's and embeddings to the dictionary for the dataframe\n    for i, r in enumerate(tensor_list_transformed):\n        curr_entry_id = esm_embeddings_df[\"EntryID\"][i]\n        embeddings_dict[\"EntryID\"].append(curr_entry_id)\n        for j in range(PCA_TARGET_DIM):\n            embeddings_dict[f\"emb_{j}\"].append(r[j])\n\n    pca_embeddings_df = pd.DataFrame(embeddings_dict)\n    return pca_embeddings_df\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T22:59:26.512310Z","iopub.execute_input":"2025-12-07T22:59:26.512568Z","iopub.status.idle":"2025-12-07T22:59:27.112645Z","shell.execute_reply.started":"2025-12-07T22:59:26.512541Z","shell.execute_reply":"2025-12-07T22:59:27.111881Z"},"id":"bGhEVeBagEhr"},"outputs":[{"name":"stdout","text":"Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D.pt\nDownloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t6_8M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D-contact-regression.pt\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"file_name = \"/kaggle/input/fasta-embeddings-final/fasta_embeddings_final.csv\"\nembeddings_processed = True\n\ndef get_merged_df_full(file_name, batch_size=250, embeddings_processed=False):\n    \"\"\"\n    Merge term.tsv, fasta data, taxonomy data as well as nodes in the obo graph.\n    \"\"\"\n    term_df = pd.read_csv(term_path, sep='\\t')\n    term_df = term_df\n    taxonomy_df = pd.read_csv(taxonomy_path, sep='\\t', names=['EntryID', 'taxonomyID'])\n    fasta_data = list(SeqIO.parse(fasta_path, \"fasta\"))\n\n    entry_ids = list(term_df['EntryID'])\n    all_batches = []\n    if not embeddings_processed:\n      for i in range(0, len(entry_ids), batch_size):\n          total_processed = i\n          print(f\"Total processed: {total_processed}, {i//batch_size} batch\")\n\n          # Batch the EntryIDs\n          entry_batch = list(set(entry_ids[i:i+batch_size]))\n\n          curr_term_df = term_df[i:i+batch_size]\n          fasta_df_batch = get_processed_fasta_df(fasta_data, curr_term_df['EntryID'])\n          fasta_emb_df_batch = generate_protein_embeddings_esm_batch(\n              fasta_df_batch,\n              \"fasta_sequence\"\n          )\n\n\n          all_batches.append(fasta_emb_df_batch)\n\n          full_df = pd.concat(all_batches, ignore_index=False)\n          full_df.to_csv(\"fasta_embeddings.csv\", index=True)\n\n    else:\n        full_df = pd.read_csv(file_name)\n        print(full_df.head())\n        \n    fasta_emb_df = apply_pca_to_esm_embeddings(full_df)\n    \n    # TODO add embeddings in getting merged_df\n    merged_df = pd.merge(term_df, fasta_emb_df, on=\"EntryID\", how='left')\n    merged_df = pd.merge(merged_df, taxonomy_df, on=\"EntryID\", how=\"left\")\n    graph = obonet.read_obo(obo_path)\n    edges_list = []\n    for node_id, data in graph.nodes(data=True):\n        for parent_id in data.get(\"is_a\", []):\n            edges_list.append({\n                    \"term\": node_id,\n                    \"parent\": parent_id,\n                    \"relation\": data.get('relation', 'is_a'),\n                    \"name\": data[\"name\"],\n                    \"namespace\": data[\"namespace\"],\n                    \"def\": data[\"def\"],\n                    \"synonym\": data.get(\"synonym\", [])\n                    \n                })\n    edges_df = pd.DataFrame(edges_list)\n    return merged_df, edges_df\n\nprotein_function_df, graph_df = get_merged_df_full(file_name, embeddings_processed=embeddings_processed)\nlen(protein_function_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:02:30.602475Z","iopub.execute_input":"2025-12-07T23:02:30.602996Z","iopub.status.idle":"2025-12-07T23:03:32.767804Z","shell.execute_reply.started":"2025-12-07T23:02:30.602970Z","shell.execute_reply":"2025-12-07T23:03:32.767206Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"nH7Ng5SXgEhr","outputId":"ddcef6f2-99d6-49db-e0d7-bababde1dda8"},"outputs":[{"name":"stdout","text":"  EntryID  prot_emb_0  prot_emb_1  prot_emb_2  prot_emb_3  prot_emb_4  \\\n0  P86164    0.063601    0.090173    0.272553    0.045446   -0.024562   \n1  P84910    0.164426   -0.128475    0.244240    0.068856   -0.031558   \n2  P83012    0.126772   -0.093400    0.216583    0.056300   -0.058426   \n3  P83246    0.039001   -0.228608    0.207255    0.138270    0.081464   \n4  P86133   -0.063519    0.141610    0.168906   -0.003960   -0.064855   \n\n   prot_emb_5  prot_emb_6  prot_emb_7  prot_emb_8  ...  prot_emb_310  \\\n0   -0.087723   -0.097689   -0.002640   -0.085523  ...      0.121198   \n1   -0.102609   -0.108406   -0.071888   -0.022300  ...      0.094619   \n2    0.006500   -0.052936   -0.012787   -0.090959  ...      0.024688   \n3   -0.122376   -0.169814   -0.090188   -0.169230  ...     -0.015823   \n4   -0.166769    0.018469    0.077215    0.058494  ...      0.147194   \n\n   prot_emb_311  prot_emb_312  prot_emb_313  prot_emb_314  prot_emb_315  \\\n0      0.150969      0.038082     -0.035188      0.107149     -0.139242   \n1     -0.008651      0.114921     -0.001714      0.107898      0.074844   \n2     -0.042868      0.107209      0.052345      0.101476      0.072974   \n3      0.006365      0.128541      0.029864      0.042600      0.003246   \n4      0.332067     -0.085424      0.030959      0.007410     -0.137569   \n\n   prot_emb_316  prot_emb_317  prot_emb_318  prot_emb_319  \n0     -0.068953      0.179406      0.029193      0.072149  \n1     -0.127740     -0.065333      0.162325     -0.015353  \n2      0.023981      0.138794     -0.027119     -0.144226  \n3      0.032807      0.189388      0.199859     -0.110070  \n4      0.025430      0.357189     -0.158802      0.058284  \n\n[5 rows x 321 columns]\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"537027"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"UNIQUE_TERMS = list(protein_function_df[\"term\"].unique())\nlen(UNIQUE_TERMS) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:53.153544Z","iopub.execute_input":"2025-12-07T23:04:53.153890Z","iopub.status.idle":"2025-12-07T23:04:53.198579Z","shell.execute_reply.started":"2025-12-07T23:04:53.153865Z","shell.execute_reply":"2025-12-07T23:04:53.197829Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"26125"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":" graph = obonet.read_obo(obo_path)\nedges_list = []\nfor node_id, data in graph.nodes(data=True):\n        for parent_id in data.get(\"is_a\", []):\n            edges_list.append({\n                    \"term\": node_id,\n                    \"parent\": parent_id,\n                    \"name\": data[\"name\"],\n                    \"namespace\": data[\"namespace\"],\n                    \"def\": data[\"def\"],\n                    \"synonym\": data.get(\"synonym\", [])\n                })\nedges_df = pd.DataFrame(edges_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:53.643582Z","iopub.execute_input":"2025-12-07T23:04:53.644112Z","iopub.status.idle":"2025-12-07T23:04:58.819725Z","shell.execute_reply.started":"2025-12-07T23:04:53.644088Z","shell.execute_reply":"2025-12-07T23:04:58.819139Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"ALL_SUBONTOLOGIES = graph_df[\"namespace\"].unique()\ngraph_df.head(\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:58.820763Z","iopub.execute_input":"2025-12-07T23:04:58.821040Z","iopub.status.idle":"2025-12-07T23:04:58.837159Z","shell.execute_reply.started":"2025-12-07T23:04:58.821022Z","shell.execute_reply":"2025-12-07T23:04:58.836567Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"         term      parent relation  \\\n0  GO:0000001  GO:0048308     is_a   \n1  GO:0000001  GO:0048311     is_a   \n2  GO:0000002  GO:0007005     is_a   \n3  GO:0000006  GO:0005385     is_a   \n4  GO:0000007  GO:0005385     is_a   \n\n                                                name           namespace  \\\n0                          mitochondrion inheritance  biological_process   \n1                          mitochondrion inheritance  biological_process   \n2                   mitochondrial genome maintenance  biological_process   \n3  high-affinity zinc transmembrane transporter a...  molecular_function   \n4  low-affinity zinc ion transmembrane transporte...  molecular_function   \n\n                                                 def  \\\n0  \"The distribution of mitochondria, including t...   \n1  \"The distribution of mitochondria, including t...   \n2  \"The maintenance of the structure and integrit...   \n3  \"Enables the transfer of zinc ions (Zn2+) from...   \n4  \"Enables the transfer of a solute or solutes f...   \n\n                                             synonym  \n0             [\"mitochondrial inheritance\" EXACT []]  \n1             [\"mitochondrial inheritance\" EXACT []]  \n2                                                 []  \n3  [\"high affinity zinc uptake transmembrane tran...  \n4                                                 []  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>parent</th>\n      <th>relation</th>\n      <th>name</th>\n      <th>namespace</th>\n      <th>def</th>\n      <th>synonym</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GO:0000001</td>\n      <td>GO:0048308</td>\n      <td>is_a</td>\n      <td>mitochondrion inheritance</td>\n      <td>biological_process</td>\n      <td>\"The distribution of mitochondria, including t...</td>\n      <td>[\"mitochondrial inheritance\" EXACT []]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GO:0000001</td>\n      <td>GO:0048311</td>\n      <td>is_a</td>\n      <td>mitochondrion inheritance</td>\n      <td>biological_process</td>\n      <td>\"The distribution of mitochondria, including t...</td>\n      <td>[\"mitochondrial inheritance\" EXACT []]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GO:0000002</td>\n      <td>GO:0007005</td>\n      <td>is_a</td>\n      <td>mitochondrial genome maintenance</td>\n      <td>biological_process</td>\n      <td>\"The maintenance of the structure and integrit...</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GO:0000006</td>\n      <td>GO:0005385</td>\n      <td>is_a</td>\n      <td>high-affinity zinc transmembrane transporter a...</td>\n      <td>molecular_function</td>\n      <td>\"Enables the transfer of zinc ions (Zn2+) from...</td>\n      <td>[\"high affinity zinc uptake transmembrane tran...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GO:0000007</td>\n      <td>GO:0005385</td>\n      <td>is_a</td>\n      <td>low-affinity zinc ion transmembrane transporte...</td>\n      <td>molecular_function</td>\n      <td>\"Enables the transfer of a solute or solutes f...</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"protein_function_df.head()","metadata":{"id":"mWU9VsYHx7oZ","outputId":"4e593628-7c94-4155-9111-bfdb21331e95","colab":{"base_uri":"https://localhost:8080/","height":771},"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:58.837750Z","iopub.execute_input":"2025-12-07T23:04:58.837963Z","iopub.status.idle":"2025-12-07T23:04:58.852239Z","shell.execute_reply.started":"2025-12-07T23:04:58.837947Z","shell.execute_reply":"2025-12-07T23:04:58.851560Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"  EntryID        term aspect     emb_0     emb_1     emb_2    emb_3     emb_4  \\\n0  Q5W0B1  GO:0000785      C -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n1  Q5W0B1  GO:0004842      F -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n2  Q5W0B1  GO:0051865      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n3  Q5W0B1  GO:0006275      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n4  Q5W0B1  GO:0006513      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n\n      emb_5     emb_6     emb_7    emb_8     emb_9    emb_10    emb_11  \\\n0 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n1 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n2 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n3 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n4 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n\n     emb_12  emb_13    emb_14    emb_15  taxonomyID  \n0 -0.117404 -0.2487 -0.039927  0.179385        9606  \n1 -0.117404 -0.2487 -0.039927  0.179385        9606  \n2 -0.117404 -0.2487 -0.039927  0.179385        9606  \n3 -0.117404 -0.2487 -0.039927  0.179385        9606  \n4 -0.117404 -0.2487 -0.039927  0.179385        9606  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>term</th>\n      <th>aspect</th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>emb_10</th>\n      <th>emb_11</th>\n      <th>emb_12</th>\n      <th>emb_13</th>\n      <th>emb_14</th>\n      <th>emb_15</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q5W0B1</td>\n      <td>GO:0000785</td>\n      <td>C</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q5W0B1</td>\n      <td>GO:0004842</td>\n      <td>F</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q5W0B1</td>\n      <td>GO:0051865</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q5W0B1</td>\n      <td>GO:0006275</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q5W0B1</td>\n      <td>GO:0006513</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"N_LARGEST = 10\ntop_terms = protein_function_df['term'].value_counts().nlargest(N_LARGEST).index\nprotein_function_top_terms_df = protein_function_df[protein_function_df['term'].isin(top_terms)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:58.853552Z","iopub.execute_input":"2025-12-07T23:04:58.853755Z","iopub.status.idle":"2025-12-07T23:04:58.960409Z","shell.execute_reply.started":"2025-12-07T23:04:58.853741Z","shell.execute_reply":"2025-12-07T23:04:58.959873Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"len(protein_function_top_terms_df), len(protein_function_df), len(graph_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:58.960986Z","iopub.execute_input":"2025-12-07T23:04:58.961185Z","iopub.status.idle":"2025-12-07T23:04:58.966189Z","shell.execute_reply.started":"2025-12-07T23:04:58.961169Z","shell.execute_reply":"2025-12-07T23:04:58.965602Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(100851, 537027, 62410)"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"### Create set of embedding from the graph edges using GCN","metadata":{"id":"W3yvSIjBY5Bf"}},{"cell_type":"code","source":"class SimpleGCN(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim):\n        super(SimpleGCN, self).__init__()\n        self.conv1 = GCNConv(in_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, out_dim)\n\n    def forward(self, x, edge_index):\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = self.conv2(x, edge_index)\n        return x\n  \ndef init_subontology_GCNs(embed_dim=16, hidden_dim=32, out_dim=16):\n    graph_subontology_dict = {\n       subontology: SimpleGCN(embed_dim, hidden_dim, out_dim) for subontology in ALL_SUBONTOLOGIES\n    }\n    return graph_subontology_dict\n\ndef get_subontology_graph_dfs(graph_df):\n    subontology_graph_dfs = {\n       subontology: graph_df[graph_df[\"namespace\"]==subontology] for subontology in ALL_SUBONTOLOGIES\n    }\n    return subontology_graph_dfs\n  \nsubontology_GCNs, subontology_graph_dfs = init_subontology_GCNs(), get_subontology_graph_dfs(graph_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:04:59.120105Z","iopub.execute_input":"2025-12-07T23:04:59.120304Z","iopub.status.idle":"2025-12-07T23:04:59.192055Z","shell.execute_reply.started":"2025-12-07T23:04:59.120289Z","shell.execute_reply":"2025-12-07T23:04:59.191479Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"protein_function_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:01.636316Z","iopub.execute_input":"2025-12-07T23:05:01.636898Z","iopub.status.idle":"2025-12-07T23:05:01.650769Z","shell.execute_reply.started":"2025-12-07T23:05:01.636872Z","shell.execute_reply":"2025-12-07T23:05:01.650231Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"  EntryID        term aspect     emb_0     emb_1     emb_2    emb_3     emb_4  \\\n0  Q5W0B1  GO:0000785      C -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n1  Q5W0B1  GO:0004842      F -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n2  Q5W0B1  GO:0051865      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n3  Q5W0B1  GO:0006275      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n4  Q5W0B1  GO:0006513      P -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n\n      emb_5     emb_6     emb_7    emb_8     emb_9    emb_10    emb_11  \\\n0 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n1 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n2 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n3 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n4 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n\n     emb_12  emb_13    emb_14    emb_15  taxonomyID  \n0 -0.117404 -0.2487 -0.039927  0.179385        9606  \n1 -0.117404 -0.2487 -0.039927  0.179385        9606  \n2 -0.117404 -0.2487 -0.039927  0.179385        9606  \n3 -0.117404 -0.2487 -0.039927  0.179385        9606  \n4 -0.117404 -0.2487 -0.039927  0.179385        9606  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>term</th>\n      <th>aspect</th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>emb_10</th>\n      <th>emb_11</th>\n      <th>emb_12</th>\n      <th>emb_13</th>\n      <th>emb_14</th>\n      <th>emb_15</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Q5W0B1</td>\n      <td>GO:0000785</td>\n      <td>C</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q5W0B1</td>\n      <td>GO:0004842</td>\n      <td>F</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q5W0B1</td>\n      <td>GO:0051865</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q5W0B1</td>\n      <td>GO:0006275</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q5W0B1</td>\n      <td>GO:0006513</td>\n      <td>P</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"def group_terms_and_aspects(protein_function_df):\n    protein_function_grouped_df = (\n        protein_function_df\n            .groupby(\"EntryID\")\n            .agg({\n                \"term\": list,                     \n                \"aspect\": list,                   \n                **{c: \"first\" for c in protein_function_top_terms_df.columns \n                   if c.startswith(\"emb_\")},      \n                \"taxonomyID\": \"first\"            \n            })\n            .rename(columns={\"term\": \"output_terms\"})\n            .reset_index()\n    )\n    return protein_function_grouped_df\n\nprotein_function_grouped_df = group_terms_and_aspects(protein_function_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:02.967137Z","iopub.execute_input":"2025-12-07T23:05:02.967819Z","iopub.status.idle":"2025-12-07T23:05:05.331288Z","shell.execute_reply.started":"2025-12-07T23:05:02.967798Z","shell.execute_reply":"2025-12-07T23:05:05.330682Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"protein_function_grouped_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:09.602361Z","iopub.execute_input":"2025-12-07T23:05:09.602902Z","iopub.status.idle":"2025-12-07T23:05:09.619715Z","shell.execute_reply.started":"2025-12-07T23:05:09.602878Z","shell.execute_reply":"2025-12-07T23:05:09.619010Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"      EntryID  output_terms aspect     emb_0     emb_1     emb_2     emb_3  \\\n0  A0A023FBW4  [GO:0019958]    [F] -0.733679 -0.278833 -0.739130 -0.129298   \n1  A0A023FBW7  [GO:0019957]    [F] -0.677593 -0.401437 -0.250645  0.016632   \n2  A0A023FDY8  [GO:0019957]    [F] -0.652475 -0.402101 -0.241203  0.076115   \n3  A0A023FF81  [GO:0019958]    [F] -0.550702 -0.327903 -0.613980 -0.264536   \n4  A0A023FFB5  [GO:0019957]    [F] -0.633638 -0.376555 -0.319808 -0.284030   \n\n      emb_4     emb_5     emb_6     emb_7     emb_8     emb_9    emb_10  \\\n0  0.640625  0.608326  0.276888  0.059629  0.456924 -0.223931  0.269701   \n1  0.365204  1.118803  0.574566 -0.098997  0.702530 -0.231559  0.155171   \n2  0.370869  1.122666  0.586032 -0.069793  0.735825 -0.261511  0.230517   \n3  0.529165  0.625794  0.384368 -0.124693  0.377998 -0.150738  0.158927   \n4  0.645544  1.141829  0.553369 -0.213995  0.667949 -0.399849  0.135954   \n\n     emb_11    emb_12    emb_13    emb_14    emb_15  taxonomyID  \n0 -0.287853 -0.389044 -0.086320  0.318142  0.208756       34607  \n1 -0.124747  0.052744 -0.021441  0.258956  0.208436       34607  \n2 -0.101076  0.027873 -0.013094  0.264486  0.208656       34607  \n3 -0.375993 -0.408175 -0.077548  0.325447  0.130539       34607  \n4 -0.303759 -0.021841 -0.024281  0.311488  0.099055       34607  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>output_terms</th>\n      <th>aspect</th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>emb_10</th>\n      <th>emb_11</th>\n      <th>emb_12</th>\n      <th>emb_13</th>\n      <th>emb_14</th>\n      <th>emb_15</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A0A023FBW4</td>\n      <td>[GO:0019958]</td>\n      <td>[F]</td>\n      <td>-0.733679</td>\n      <td>-0.278833</td>\n      <td>-0.739130</td>\n      <td>-0.129298</td>\n      <td>0.640625</td>\n      <td>0.608326</td>\n      <td>0.276888</td>\n      <td>0.059629</td>\n      <td>0.456924</td>\n      <td>-0.223931</td>\n      <td>0.269701</td>\n      <td>-0.287853</td>\n      <td>-0.389044</td>\n      <td>-0.086320</td>\n      <td>0.318142</td>\n      <td>0.208756</td>\n      <td>34607</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A0A023FBW7</td>\n      <td>[GO:0019957]</td>\n      <td>[F]</td>\n      <td>-0.677593</td>\n      <td>-0.401437</td>\n      <td>-0.250645</td>\n      <td>0.016632</td>\n      <td>0.365204</td>\n      <td>1.118803</td>\n      <td>0.574566</td>\n      <td>-0.098997</td>\n      <td>0.702530</td>\n      <td>-0.231559</td>\n      <td>0.155171</td>\n      <td>-0.124747</td>\n      <td>0.052744</td>\n      <td>-0.021441</td>\n      <td>0.258956</td>\n      <td>0.208436</td>\n      <td>34607</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A0A023FDY8</td>\n      <td>[GO:0019957]</td>\n      <td>[F]</td>\n      <td>-0.652475</td>\n      <td>-0.402101</td>\n      <td>-0.241203</td>\n      <td>0.076115</td>\n      <td>0.370869</td>\n      <td>1.122666</td>\n      <td>0.586032</td>\n      <td>-0.069793</td>\n      <td>0.735825</td>\n      <td>-0.261511</td>\n      <td>0.230517</td>\n      <td>-0.101076</td>\n      <td>0.027873</td>\n      <td>-0.013094</td>\n      <td>0.264486</td>\n      <td>0.208656</td>\n      <td>34607</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A0A023FF81</td>\n      <td>[GO:0019958]</td>\n      <td>[F]</td>\n      <td>-0.550702</td>\n      <td>-0.327903</td>\n      <td>-0.613980</td>\n      <td>-0.264536</td>\n      <td>0.529165</td>\n      <td>0.625794</td>\n      <td>0.384368</td>\n      <td>-0.124693</td>\n      <td>0.377998</td>\n      <td>-0.150738</td>\n      <td>0.158927</td>\n      <td>-0.375993</td>\n      <td>-0.408175</td>\n      <td>-0.077548</td>\n      <td>0.325447</td>\n      <td>0.130539</td>\n      <td>34607</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A0A023FFB5</td>\n      <td>[GO:0019957]</td>\n      <td>[F]</td>\n      <td>-0.633638</td>\n      <td>-0.376555</td>\n      <td>-0.319808</td>\n      <td>-0.284030</td>\n      <td>0.645544</td>\n      <td>1.141829</td>\n      <td>0.553369</td>\n      <td>-0.213995</td>\n      <td>0.667949</td>\n      <td>-0.399849</td>\n      <td>0.135954</td>\n      <td>-0.303759</td>\n      <td>-0.021841</td>\n      <td>-0.024281</td>\n      <td>0.311488</td>\n      <td>0.099055</td>\n      <td>34607</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"protein_function_grouped_df[protein_function_grouped_df[\"EntryID\"] == \"Q5W0B1\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:11.700612Z","iopub.execute_input":"2025-12-07T23:05:11.701332Z","iopub.status.idle":"2025-12-07T23:05:11.727633Z","shell.execute_reply.started":"2025-12-07T23:05:11.701308Z","shell.execute_reply":"2025-12-07T23:05:11.726710Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"      EntryID                                       output_terms  \\\n48432  Q5W0B1  [GO:0000785, GO:0004842, GO:0051865, GO:000627...   \n\n                      aspect     emb_0     emb_1     emb_2    emb_3     emb_4  \\\n48432  [C, F, P, P, P, F, F] -0.270628  1.031287 -0.162849 -0.90439 -0.347545   \n\n          emb_5     emb_6     emb_7    emb_8     emb_9    emb_10    emb_11  \\\n48432 -0.220611  0.036556 -0.221058  0.19175  0.372038  0.575382 -0.200636   \n\n         emb_12  emb_13    emb_14    emb_15  taxonomyID  \n48432 -0.117404 -0.2487 -0.039927  0.179385        9606  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>output_terms</th>\n      <th>aspect</th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>emb_10</th>\n      <th>emb_11</th>\n      <th>emb_12</th>\n      <th>emb_13</th>\n      <th>emb_14</th>\n      <th>emb_15</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>48432</th>\n      <td>Q5W0B1</td>\n      <td>[GO:0000785, GO:0004842, GO:0051865, GO:000627...</td>\n      <td>[C, F, P, P, P, F, F]</td>\n      <td>-0.270628</td>\n      <td>1.031287</td>\n      <td>-0.162849</td>\n      <td>-0.90439</td>\n      <td>-0.347545</td>\n      <td>-0.220611</td>\n      <td>0.036556</td>\n      <td>-0.221058</td>\n      <td>0.19175</td>\n      <td>0.372038</td>\n      <td>0.575382</td>\n      <td>-0.200636</td>\n      <td>-0.117404</td>\n      <td>-0.2487</td>\n      <td>-0.039927</td>\n      <td>0.179385</td>\n      <td>9606</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"protein_function_grouped_df = protein_function_grouped_df.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:13.448209Z","iopub.execute_input":"2025-12-07T23:05:13.448932Z","iopub.status.idle":"2025-12-07T23:05:13.496874Z","shell.execute_reply.started":"2025-12-07T23:05:13.448903Z","shell.execute_reply":"2025-12-07T23:05:13.496268Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"protein_function_grouped_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:05:13.816391Z","iopub.execute_input":"2025-12-07T23:05:13.817047Z","iopub.status.idle":"2025-12-07T23:05:13.832375Z","shell.execute_reply.started":"2025-12-07T23:05:13.817019Z","shell.execute_reply":"2025-12-07T23:05:13.831780Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"  EntryID                                       output_terms           aspect  \\\n0  P04268               [GO:0005515, GO:0005886, GO:0008092]        [F, C, F]   \n1  Q8LAP6  [GO:0005634, GO:0009507, GO:0009534, GO:000953...  [C, C, C, C, C]   \n2  Q03489                                       [GO:0005515]              [F]   \n3  Q96PQ6                           [GO:0005515, GO:0005634]           [F, C]   \n4  Q59RK9  [GO:0008233, GO:0005739, GO:0042775, GO:004401...  [F, C, P, P, P]   \n\n      emb_0     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n0  0.828323  0.703457  1.160203 -0.054023 -0.939162 -1.085810  1.780389   \n1 -0.793946 -0.121416  0.264455 -0.091416  0.171004  0.079607  0.149902   \n2 -0.825974  0.277098 -0.046827 -0.155165 -0.192515 -0.353548  0.237032   \n3  1.056239  1.366326 -0.094833 -0.112145 -0.218979  0.265883  0.452629   \n4 -0.249164 -0.473922  0.326476 -0.376346 -0.044497 -0.192280 -0.052922   \n\n      emb_7     emb_8     emb_9    emb_10    emb_11    emb_12    emb_13  \\\n0  0.795923  0.361770  0.317409 -0.095173 -0.350046 -0.512594 -0.313681   \n1 -0.034930 -0.256049  0.294488  0.015121 -0.285039 -0.168807  0.164656   \n2  0.520949  0.298848 -0.230937 -0.166167  0.181591 -0.110926 -0.025534   \n3  0.542162  0.305502  0.255235 -0.147662  0.492993  0.423559 -0.004679   \n4 -0.022000 -0.123031 -0.181675  0.263037  0.056715 -0.134725  0.348870   \n\n     emb_14    emb_15  taxonomyID  \n0  0.097373  0.833666        9031  \n1 -0.089438 -0.239670        3702  \n2  0.032579 -0.221545        4102  \n3 -0.289698  0.479508        9606  \n4  0.097481 -0.156761      237561  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EntryID</th>\n      <th>output_terms</th>\n      <th>aspect</th>\n      <th>emb_0</th>\n      <th>emb_1</th>\n      <th>emb_2</th>\n      <th>emb_3</th>\n      <th>emb_4</th>\n      <th>emb_5</th>\n      <th>emb_6</th>\n      <th>emb_7</th>\n      <th>emb_8</th>\n      <th>emb_9</th>\n      <th>emb_10</th>\n      <th>emb_11</th>\n      <th>emb_12</th>\n      <th>emb_13</th>\n      <th>emb_14</th>\n      <th>emb_15</th>\n      <th>taxonomyID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P04268</td>\n      <td>[GO:0005515, GO:0005886, GO:0008092]</td>\n      <td>[F, C, F]</td>\n      <td>0.828323</td>\n      <td>0.703457</td>\n      <td>1.160203</td>\n      <td>-0.054023</td>\n      <td>-0.939162</td>\n      <td>-1.085810</td>\n      <td>1.780389</td>\n      <td>0.795923</td>\n      <td>0.361770</td>\n      <td>0.317409</td>\n      <td>-0.095173</td>\n      <td>-0.350046</td>\n      <td>-0.512594</td>\n      <td>-0.313681</td>\n      <td>0.097373</td>\n      <td>0.833666</td>\n      <td>9031</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Q8LAP6</td>\n      <td>[GO:0005634, GO:0009507, GO:0009534, GO:000953...</td>\n      <td>[C, C, C, C, C]</td>\n      <td>-0.793946</td>\n      <td>-0.121416</td>\n      <td>0.264455</td>\n      <td>-0.091416</td>\n      <td>0.171004</td>\n      <td>0.079607</td>\n      <td>0.149902</td>\n      <td>-0.034930</td>\n      <td>-0.256049</td>\n      <td>0.294488</td>\n      <td>0.015121</td>\n      <td>-0.285039</td>\n      <td>-0.168807</td>\n      <td>0.164656</td>\n      <td>-0.089438</td>\n      <td>-0.239670</td>\n      <td>3702</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Q03489</td>\n      <td>[GO:0005515]</td>\n      <td>[F]</td>\n      <td>-0.825974</td>\n      <td>0.277098</td>\n      <td>-0.046827</td>\n      <td>-0.155165</td>\n      <td>-0.192515</td>\n      <td>-0.353548</td>\n      <td>0.237032</td>\n      <td>0.520949</td>\n      <td>0.298848</td>\n      <td>-0.230937</td>\n      <td>-0.166167</td>\n      <td>0.181591</td>\n      <td>-0.110926</td>\n      <td>-0.025534</td>\n      <td>0.032579</td>\n      <td>-0.221545</td>\n      <td>4102</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Q96PQ6</td>\n      <td>[GO:0005515, GO:0005634]</td>\n      <td>[F, C]</td>\n      <td>1.056239</td>\n      <td>1.366326</td>\n      <td>-0.094833</td>\n      <td>-0.112145</td>\n      <td>-0.218979</td>\n      <td>0.265883</td>\n      <td>0.452629</td>\n      <td>0.542162</td>\n      <td>0.305502</td>\n      <td>0.255235</td>\n      <td>-0.147662</td>\n      <td>0.492993</td>\n      <td>0.423559</td>\n      <td>-0.004679</td>\n      <td>-0.289698</td>\n      <td>0.479508</td>\n      <td>9606</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Q59RK9</td>\n      <td>[GO:0008233, GO:0005739, GO:0042775, GO:004401...</td>\n      <td>[F, C, P, P, P]</td>\n      <td>-0.249164</td>\n      <td>-0.473922</td>\n      <td>0.326476</td>\n      <td>-0.376346</td>\n      <td>-0.044497</td>\n      <td>-0.192280</td>\n      <td>-0.052922</td>\n      <td>-0.022000</td>\n      <td>-0.123031</td>\n      <td>-0.181675</td>\n      <td>0.263037</td>\n      <td>0.056715</td>\n      <td>-0.134725</td>\n      <td>0.348870</td>\n      <td>0.097481</td>\n      <td>-0.156761</td>\n      <td>237561</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"protein_function_grouped_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:23:56.470428Z","iopub.execute_input":"2025-12-07T23:23:56.471375Z","iopub.status.idle":"2025-12-07T23:23:56.476773Z","shell.execute_reply.started":"2025-12-07T23:23:56.471341Z","shell.execute_reply":"2025-12-07T23:23:56.475896Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"Index(['EntryID', 'output_terms', 'aspect', 'emb_0', 'emb_1', 'emb_2', 'emb_3',\n       'emb_4', 'emb_5', 'emb_6', 'emb_7', 'emb_8', 'emb_9', 'emb_10',\n       'emb_11', 'emb_12', 'emb_13', 'emb_14', 'emb_15', 'taxonomyID'],\n      dtype='object')"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Columns for Training and Columns for Testing\nPREDICTORS = [f\"emb_{i}\" for i in range(PCA_TARGET_DIM)]\nOUTPUTS = ['output_terms']\n\nX, y = protein_function_grouped_df[PREDICTORS].values, protein_function_grouped_df[OUTPUTS].iloc[:, 0].tolist()\n\nX_train_all, X_test, y_train_all, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n# Perform a second split for validation set for finetuning our model\nX_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=0.1, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:23:56.883685Z","iopub.execute_input":"2025-12-07T23:23:56.884404Z","iopub.status.idle":"2025-12-07T23:23:56.946734Z","shell.execute_reply.started":"2025-12-07T23:23:56.884372Z","shell.execute_reply":"2025-12-07T23:23:56.945976Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"X_train[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:23:57.687713Z","iopub.execute_input":"2025-12-07T23:23:57.688539Z","iopub.status.idle":"2025-12-07T23:23:57.694476Z","shell.execute_reply.started":"2025-12-07T23:23:57.688514Z","shell.execute_reply":"2025-12-07T23:23:57.693644Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"array([[-0.49296213, -0.01622331, -1.11866516, -0.15020773,  0.12439647,\n         0.05385924,  0.46113253,  0.13634784,  0.24280338, -0.25606162,\n         0.19629219,  0.22369397, -0.09851923, -0.30465693,  0.0637247 ,\n        -0.01058716],\n       [-0.5841194 ,  1.48870603,  0.75834594,  0.05783931,  0.99029331,\n        -0.52127981, -0.57595586, -0.43504412, -0.30822012, -0.18575208,\n         0.521059  ,  0.07723638, -0.31320555,  0.04521012, -0.28043838,\n         0.30554427],\n       [-0.3261771 ,  0.01603119,  0.21448599, -0.44926922, -0.34283228,\n        -0.47060042,  0.42721508,  0.13151672,  0.04128078, -0.16860942,\n         0.24420281, -0.34340918,  0.14533351,  0.21044341,  0.00492799,\n        -0.26236739],\n       [ 0.8045573 ,  0.65480441, -0.60428037,  0.14623947,  0.16293909,\n         0.13174626,  0.08809055,  0.00480766, -0.65053608, -0.10848213,\n        -0.20525797, -0.32964627, -0.15859557, -0.07507067, -0.42614259,\n         0.00841828],\n       [ 0.12646678, -0.33089076, -0.17256239, -0.33085627,  0.16438052,\n         0.22679775, -0.26831275, -0.18214746,  0.11792331, -0.34712709,\n        -0.17633787, -0.10949066, -0.09124115, -0.01030191, -0.02153771,\n         0.55027083]])"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"y_train[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:23:58.446887Z","iopub.execute_input":"2025-12-07T23:23:58.447168Z","iopub.status.idle":"2025-12-07T23:23:58.453024Z","shell.execute_reply.started":"2025-12-07T23:23:58.447148Z","shell.execute_reply":"2025-12-07T23:23:58.452295Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"[['GO:0030514',\n  'GO:0045668',\n  'GO:0005886',\n  'GO:0005515',\n  'GO:0005737',\n  'GO:0016477',\n  'GO:0030512',\n  'GO:0045893',\n  'GO:0090263',\n  'GO:0005114',\n  'GO:0010718',\n  'GO:0008284',\n  'GO:0008360',\n  'GO:0005109'],\n ['GO:0005829'],\n ['GO:0005829',\n  'GO:0005515',\n  'GO:1905821',\n  'GO:0000796',\n  'GO:0007076',\n  'GO:0016020'],\n ['GO:0009986',\n  'GO:0005515',\n  'GO:0098793',\n  'GO:0098794',\n  'GO:0099175',\n  'GO:0098685',\n  'GO:0050804'],\n ['GO:0006493',\n  'GO:0009247',\n  'GO:0048531',\n  'GO:1902037',\n  'GO:0016263',\n  'GO:0021551',\n  'GO:0051489',\n  'GO:0007528',\n  'GO:0055001',\n  'GO:0042803',\n  'GO:0030145']]"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\nterm_to_index = {term: i for i, term in enumerate(UNIQUE_TERMS)}\n\nmlb = MultiLabelBinarizer(classes=UNIQUE_TERMS)\ny_train_transformed = mlb.fit_transform(y_train)\ny_val_transformed = mlb.transform(y_val)\n\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"constant\", fill_value=0)\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\nX_val_imputed = imputer.transform(X_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:27:58.268657Z","iopub.execute_input":"2025-12-07T23:27:58.269227Z","iopub.status.idle":"2025-12-07T23:27:59.304950Z","shell.execute_reply.started":"2025-12-07T23:27:58.269200Z","shell.execute_reply":"2025-12-07T23:27:59.304175Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"import xgboost as xgb\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\n\nnum_models = 100\n\n\ndef train_xgb_models():\n    models = []\n    for i in range(num_models):\n        print(f\"\\nTraining model for label {i}...\")\n    \n        y_i = y_train_transformed[:, i]\n    \n        pos = np.sum(y_i == 1)\n        neg = np.sum(y_i == 0)\n        scale_pos_weight = neg / pos if pos > 0 else 1.0\n    \n        print(f\"Label {i} imbalance pos={pos}, neg={neg}, scaling weight={scale_pos_weight}\")\n    \n        dtrain = xgb.DMatrix(X_train_imputed, label=y_i)\n    \n        params = {\n            \"objective\": \"binary:logistic\",\n            \"eval_metric\": \"aucpr\",\n            \"tree_method\": \"hist\",\n            \"max_depth\": 7,\n            \"eta\": 0.05,\n            \"lambda\": 1.5,\n            \"alpha\": 0.8,\n            \"min_child_weight\": 2,\n            \"subsample\": 0.8,\n            \"colsample_bytree\": 0.8,\n            \"scale_pos_weight\": scale_pos_weight\n        }\n    \n        model = xgb.train(\n            params=params,\n            dtrain=dtrain,\n            num_boost_round=300,\n            evals=[(dtrain, \"train\")],\n            early_stopping_rounds=25,\n            verbose_eval=50\n        )\n    \n        models.append(model)\n    return models\n\ndef train_logistic_regression_models():\n    models = []\n    \n    for i in range(num_models):\n        print(f\"\\nTraining model for label {i}...\")\n    \n        y_i = y_train_transformed[:, i]\n    \n        pos = np.sum(y_i == 1)\n        neg = np.sum(y_i == 0)\n        scale_pos_weight = neg / pos if pos > 0 else 1.0\n    \n        print(f\"Label {i} imbalance pos={pos}, neg={neg}, scaling weight={scale_pos_weight}\")\n    \n        model = LogisticRegression(\n            penalty=\"l2\",\n            solver=\"liblinear\",\n            class_weight={0: 1.0, 1: scale_pos_weight},\n            max_iter=200\n        )\n    \n        model.fit(X_train_imputed, y_i)\n        models.append(model)\n    return models\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:43:29.636927Z","iopub.execute_input":"2025-12-07T23:43:29.637580Z","iopub.status.idle":"2025-12-07T23:43:29.645097Z","shell.execute_reply.started":"2025-12-07T23:43:29.637555Z","shell.execute_reply":"2025-12-07T23:43:29.644316Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"dval = xgb.DMatrix(X_val)\n\n\nxgb_pred_list = []\nfor model in xgboost_models:\n    print(f\"model: {model}\")\n    xgb_pred_list.append(model.predict(dval))\n\nxgb_preds = np.column_stack(xgb_pred_list)\n\nlr_pred_list = []\nfor model in logistic_regression_models:\n    print(f\"model: {model}\")\n    lr_pred_list.append(model.predict(X_val_imputed))\n\nlr_preds = np.column_stack(lr_pred_list)\n\nmodel_predictions_dict = {\n    \"xgb_preds\": xgb_preds,\n    \"lr_preds\": lr_preds\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:46:42.212672Z","iopub.execute_input":"2025-12-07T23:46:42.212977Z","iopub.status.idle":"2025-12-07T23:46:42.705286Z","shell.execute_reply.started":"2025-12-07T23:46:42.212954Z","shell.execute_reply":"2025-12-07T23:46:42.704652Z"}},"outputs":[{"name":"stdout","text":"model: <xgboost.core.Booster object at 0x7f5b9a954b90>\nmodel: <xgboost.core.Booster object at 0x7f5b972cc550>\nmodel: <xgboost.core.Booster object at 0x7f5b9a9cd910>\nmodel: <xgboost.core.Booster object at 0x7f5b971b6610>\nmodel: <xgboost.core.Booster object at 0x7f5bbae9b710>\nmodel: <xgboost.core.Booster object at 0x7f5b972cf790>\nmodel: <xgboost.core.Booster object at 0x7f5b9a948850>\nmodel: <xgboost.core.Booster object at 0x7f5b981adf90>\nmodel: <xgboost.core.Booster object at 0x7f5b974a0dd0>\nmodel: <xgboost.core.Booster object at 0x7f5bbac25e10>\nmodel: <xgboost.core.Booster object at 0x7f5bb9d09450>\nmodel: <xgboost.core.Booster object at 0x7f5bec32dfd0>\nmodel: <xgboost.core.Booster object at 0x7f5b972cf9d0>\nmodel: <xgboost.core.Booster object at 0x7f5b972d7610>\nmodel: <xgboost.core.Booster object at 0x7f5b972cc510>\nmodel: <xgboost.core.Booster object at 0x7f5b9a9cd790>\nmodel: <xgboost.core.Booster object at 0x7f5bec34bb10>\nmodel: <xgboost.core.Booster object at 0x7f5b98cc1990>\nmodel: <xgboost.core.Booster object at 0x7f5b9749d890>\nmodel: <xgboost.core.Booster object at 0x7f5bb9d09050>\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 87.0675}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 182.95300261096605}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 781.8222222222222}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1676.4761904761904}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 977.5277777777778}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 106.56335877862595}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1.4516824999130042}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 938.3866666666667}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 38.8045197740113}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 3707.1052631578946}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1082.9076923076923}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 14089.8}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 213.7987804878049}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2428.448275862069}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2708.769230769231}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7827.222222222223}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2817.16}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 8805.75}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2817.16}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1082.9076923076923}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 22.08453473132372}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 5031.428571428572}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 3913.1111111111113}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7044.4}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7044.4}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 381.9021739130435}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1257.107142857143}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 902.2564102564103}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 596.0677966101695}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1099.84375}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 319.24545454545455}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 902.2564102564103}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1257.107142857143}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7.114950472241419}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 8805.75}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7827.222222222223}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 14089.8}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 5.330667625123551}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 837.7380952380952}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1082.9076923076923}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 520.8814814814815}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 11741.333333333334}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1257.107142857143}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 24.480650994575043}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7.683017007641114}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1853.0526315789473}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 245.34265734265733}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 143.66940451745378}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 622.4867256637168}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 27.96957236842105}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1235.0350877192982}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7044.4}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 15.361820715281004}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 5.208494888967219}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2708.769230769231}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 21.97163351809586}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1066.4848484848485}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 323.6728110599078}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 3521.7}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 3913.1111111111113}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 70453.0}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2708.769230769231}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 4143.35294117647}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1193.135593220339}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1303.7037037037037}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1436.8367346938776}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 102.76141384388806}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1600.2272727272727}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 55.45352564102564}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 77.10864745011087}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 683.0194174757281}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 281.9477911646586}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 740.6210526315789}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 23483.666666666668}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1676.4761904761904}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 447.7515923566879}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 297.53389830508473}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 406.2485549132948}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 13.328655684360383}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 70453.0}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 35226.0}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 11741.333333333334}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 14089.8}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1135.3548387096773}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1380.450980392157}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 453.541935483871}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1805.5128205128206}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 3521.7}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 11741.333333333334}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 7827.222222222223}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 14089.8}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 225.54019292604502}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1853.0526315789473}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 764.804347826087}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1005.4857142857143}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 1530.608695652174}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 2515.214285714286}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 199.72364672364674}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 134.48846153846154}, max_iter=200,\n                   solver='liblinear')\nmodel: LogisticRegression(class_weight={0: 1.0, 1: 596.0677966101695}, max_iter=200,\n                   solver='liblinear')\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\nfor k, v in model_predictions_dict.items():\n    pred_binary = (v >= 0.5).astype(int)\n    \n    y_true = y_val_transformed[:, :num_models]\n    \n    accuracy_per_label = []\n    f1_per_label = []\n\n    for i in range(len(pred_binary[0])):\n        acc = accuracy_score(y_true[:, i], pred_binary[:, i])\n        f1  = f1_score(y_true[:, i], pred_binary[:, i], zero_division=0)\n    \n        accuracy_per_label.append(acc)\n        f1_per_label.append(f1)\n    \n        print(f\"Model: {k} Label {i}:  Accuracy = {acc:.4f},   F1 = {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T23:50:58.232798Z","iopub.execute_input":"2025-12-07T23:50:58.233595Z","iopub.status.idle":"2025-12-07T23:50:58.945805Z","shell.execute_reply.started":"2025-12-07T23:50:58.233565Z","shell.execute_reply":"2025-12-07T23:50:58.945141Z"}},"outputs":[{"name":"stdout","text":"Model: xgb_preds Label 0:  Accuracy = 0.9599,   F1 = 0.0977\nModel: xgb_preds Label 1:  Accuracy = 0.9894,   F1 = 0.3025\nModel: xgb_preds Label 2:  Accuracy = 0.9954,   F1 = 0.0000\nModel: xgb_preds Label 3:  Accuracy = 0.9986,   F1 = 0.0000\nModel: xgb_preds Label 4:  Accuracy = 0.9987,   F1 = 0.1667\nModel: xgb_preds Label 5:  Accuracy = 0.9670,   F1 = 0.1400\nModel: xgb_preds Label 6:  Accuracy = 0.6647,   F1 = 0.6331\nModel: xgb_preds Label 7:  Accuracy = 0.9981,   F1 = 0.1176\nModel: xgb_preds Label 8:  Accuracy = 0.9157,   F1 = 0.1771\nModel: xgb_preds Label 9:  Accuracy = 0.9991,   F1 = 0.4615\nModel: xgb_preds Label 10:  Accuracy = 0.9990,   F1 = 0.6000\nModel: xgb_preds Label 11:  Accuracy = 1.0000,   F1 = 0.0000\nModel: xgb_preds Label 12:  Accuracy = 0.9891,   F1 = 0.2478\nModel: xgb_preds Label 13:  Accuracy = 0.9997,   F1 = 0.5000\nModel: xgb_preds Label 14:  Accuracy = 0.9940,   F1 = 0.0784\nModel: xgb_preds Label 15:  Accuracy = 0.9997,   F1 = 0.0000\nModel: xgb_preds Label 16:  Accuracy = 0.9953,   F1 = 0.1395\nModel: xgb_preds Label 17:  Accuracy = 0.9997,   F1 = 0.0000\nModel: xgb_preds Label 18:  Accuracy = 0.9980,   F1 = 0.0000\nModel: xgb_preds Label 19:  Accuracy = 0.9626,   F1 = 0.0579\nModel: lr_preds Label 0:  Accuracy = 0.6851,   F1 = 0.0595\nModel: lr_preds Label 1:  Accuracy = 0.6765,   F1 = 0.0239\nModel: lr_preds Label 2:  Accuracy = 0.7328,   F1 = 0.0038\nModel: lr_preds Label 3:  Accuracy = 0.7093,   F1 = 0.0044\nModel: lr_preds Label 4:  Accuracy = 0.6822,   F1 = 0.0024\nModel: lr_preds Label 5:  Accuracy = 0.7370,   F1 = 0.0525\nModel: lr_preds Label 6:  Accuracy = 0.6480,   F1 = 0.6063\nModel: lr_preds Label 7:  Accuracy = 0.7545,   F1 = 0.0031\nModel: lr_preds Label 8:  Accuracy = 0.6051,   F1 = 0.0630\nModel: lr_preds Label 9:  Accuracy = 0.9862,   F1 = 0.0690\nModel: lr_preds Label 10:  Accuracy = 0.8184,   F1 = 0.0111\nModel: lr_preds Label 11:  Accuracy = 0.9963,   F1 = 0.0000\nModel: lr_preds Label 12:  Accuracy = 0.7803,   F1 = 0.0326\nModel: lr_preds Label 13:  Accuracy = 0.8889,   F1 = 0.0023\nModel: lr_preds Label 14:  Accuracy = 0.8449,   F1 = 0.0049\nModel: lr_preds Label 15:  Accuracy = 0.9400,   F1 = 0.0000\nModel: lr_preds Label 16:  Accuracy = 0.8958,   F1 = 0.0097\nModel: lr_preds Label 17:  Accuracy = 0.9941,   F1 = 0.0417\nModel: lr_preds Label 18:  Accuracy = 0.8227,   F1 = 0.0000\nModel: lr_preds Label 19:  Accuracy = 0.8361,   F1 = 0.0153\nModel: lr_preds Label 20:  Accuracy = 0.6715,   F1 = 0.1409\nModel: lr_preds Label 21:  Accuracy = 0.8659,   F1 = 0.0000\nModel: lr_preds Label 22:  Accuracy = 0.8573,   F1 = 0.0036\nModel: lr_preds Label 23:  Accuracy = 0.9160,   F1 = 0.0060\nModel: lr_preds Label 24:  Accuracy = 0.9239,   F1 = 0.0100\nModel: lr_preds Label 25:  Accuracy = 0.6724,   F1 = 0.0085\nModel: lr_preds Label 26:  Accuracy = 0.7951,   F1 = 0.0050\nModel: lr_preds Label 27:  Accuracy = 0.9092,   F1 = 0.0327\nModel: lr_preds Label 28:  Accuracy = 0.6992,   F1 = 0.0117\nModel: lr_preds Label 29:  Accuracy = 0.6950,   F1 = 0.0050\nModel: lr_preds Label 30:  Accuracy = 0.6643,   F1 = 0.0113\nModel: lr_preds Label 31:  Accuracy = 0.7083,   F1 = 0.0035\nModel: lr_preds Label 32:  Accuracy = 0.8610,   F1 = 0.0073\nModel: lr_preds Label 33:  Accuracy = 0.7380,   F1 = 0.3843\nModel: lr_preds Label 34:  Accuracy = 0.9281,   F1 = 0.0035\nModel: lr_preds Label 35:  Accuracy = 0.8803,   F1 = 0.0021\nModel: lr_preds Label 36:  Accuracy = 0.9324,   F1 = 0.0000\nModel: lr_preds Label 37:  Accuracy = 0.5805,   F1 = 0.3633\nModel: lr_preds Label 38:  Accuracy = 0.7691,   F1 = 0.0055\nModel: lr_preds Label 39:  Accuracy = 0.8165,   F1 = 0.0042\nModel: lr_preds Label 40:  Accuracy = 0.7803,   F1 = 0.0194\nModel: lr_preds Label 41:  Accuracy = 0.9624,   F1 = 0.0000\nModel: lr_preds Label 42:  Accuracy = 0.7545,   F1 = 0.0083\nModel: lr_preds Label 43:  Accuracy = 0.7932,   F1 = 0.2316\nModel: lr_preds Label 44:  Accuracy = 0.5552,   F1 = 0.2703\nModel: lr_preds Label 45:  Accuracy = 0.8728,   F1 = 0.0060\nModel: lr_preds Label 46:  Accuracy = 0.7251,   F1 = 0.0209\nModel: lr_preds Label 47:  Accuracy = 0.6160,   F1 = 0.0240\nModel: lr_preds Label 48:  Accuracy = 0.6901,   F1 = 0.0082\nModel: lr_preds Label 49:  Accuracy = 0.6880,   F1 = 0.1222\nModel: lr_preds Label 50:  Accuracy = 0.7411,   F1 = 0.0078\nModel: lr_preds Label 51:  Accuracy = 0.9799,   F1 = 0.0000\nModel: lr_preds Label 52:  Accuracy = 0.7057,   F1 = 0.2366\nModel: lr_preds Label 53:  Accuracy = 0.6728,   F1 = 0.4352\nModel: lr_preds Label 54:  Accuracy = 0.7932,   F1 = 0.0000\nModel: lr_preds Label 55:  Accuracy = 0.6090,   F1 = 0.1068\nModel: lr_preds Label 56:  Accuracy = 0.6158,   F1 = 0.0046\nModel: lr_preds Label 57:  Accuracy = 0.6394,   F1 = 0.0070\nModel: lr_preds Label 58:  Accuracy = 0.8612,   F1 = 0.0037\nModel: lr_preds Label 59:  Accuracy = 0.7632,   F1 = 0.0022\nModel: lr_preds Label 60:  Accuracy = 0.9911,   F1 = 0.0000\nModel: lr_preds Label 61:  Accuracy = 0.8650,   F1 = 0.0038\nModel: lr_preds Label 62:  Accuracy = 0.8922,   F1 = 0.0024\nModel: lr_preds Label 63:  Accuracy = 0.7646,   F1 = 0.0086\nModel: lr_preds Label 64:  Accuracy = 0.7060,   F1 = 0.0026\nModel: lr_preds Label 65:  Accuracy = 0.6274,   F1 = 0.0027\nModel: lr_preds Label 66:  Accuracy = 0.6883,   F1 = 0.0446\nModel: lr_preds Label 67:  Accuracy = 0.7562,   F1 = 0.0042\nModel: lr_preds Label 68:  Accuracy = 0.7896,   F1 = 0.1497\nModel: lr_preds Label 69:  Accuracy = 0.7129,   F1 = 0.0711\nModel: lr_preds Label 70:  Accuracy = 0.7434,   F1 = 0.0108\nModel: lr_preds Label 71:  Accuracy = 0.6934,   F1 = 0.0083\nModel: lr_preds Label 72:  Accuracy = 0.7291,   F1 = 0.0056\nModel: lr_preds Label 73:  Accuracy = 0.9729,   F1 = 0.0000\nModel: lr_preds Label 74:  Accuracy = 0.8004,   F1 = 0.0026\nModel: lr_preds Label 75:  Accuracy = 0.8258,   F1 = 0.0326\nModel: lr_preds Label 76:  Accuracy = 0.8276,   F1 = 0.0439\nModel: lr_preds Label 77:  Accuracy = 0.8626,   F1 = 0.0393\nModel: lr_preds Label 78:  Accuracy = 0.6601,   F1 = 0.2399\nModel: lr_preds Label 79:  Accuracy = 0.9918,   F1 = 0.0000\nModel: lr_preds Label 80:  Accuracy = 0.9863,   F1 = 0.0000\nModel: lr_preds Label 81:  Accuracy = 0.8857,   F1 = 0.0000\nModel: lr_preds Label 82:  Accuracy = 0.9253,   F1 = 0.0000\nModel: lr_preds Label 83:  Accuracy = 0.7521,   F1 = 0.0031\nModel: lr_preds Label 84:  Accuracy = 0.7717,   F1 = 0.0045\nModel: lr_preds Label 85:  Accuracy = 0.6683,   F1 = 0.0092\nModel: lr_preds Label 86:  Accuracy = 0.7550,   F1 = 0.0042\nModel: lr_preds Label 87:  Accuracy = 0.7900,   F1 = 0.0012\nModel: lr_preds Label 88:  Accuracy = 0.9977,   F1 = 0.0000\nModel: lr_preds Label 89:  Accuracy = 0.8466,   F1 = 0.0017\nModel: lr_preds Label 90:  Accuracy = 0.9475,   F1 = 0.0000\nModel: lr_preds Label 91:  Accuracy = 0.6964,   F1 = 0.0222\nModel: lr_preds Label 92:  Accuracy = 0.7000,   F1 = 0.0025\nModel: lr_preds Label 93:  Accuracy = 0.8271,   F1 = 0.0102\nModel: lr_preds Label 94:  Accuracy = 0.7559,   F1 = 0.0031\nModel: lr_preds Label 95:  Accuracy = 0.8161,   F1 = 0.0069\nModel: lr_preds Label 96:  Accuracy = 0.8331,   F1 = 0.0015\nModel: lr_preds Label 97:  Accuracy = 0.7158,   F1 = 0.0168\nModel: lr_preds Label 98:  Accuracy = 0.8746,   F1 = 0.0874\nModel: lr_preds Label 99:  Accuracy = 0.8719,   F1 = 0.0157\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"def create_go_embeddings_optimized(obo_path, go_terms, embed_dim=16, hidden_dim=32, out_dim=16, epochs=50):\n\n    print(\" Loading Gene Ontology...\")\n    graph = obonet.read_obo(obo_path)\n\n\n    edges = pd.DataFrame([\n        {'source': u, 'target': v, 'relation': data.get('relation', 'is_a')}\n        for u, v, data in graph.edges(data=True)\n    ])\n\n    relevant_edges = edges[\n        edges['source'].isin(go_terms) | edges['target'].isin(go_terms)\n    ].reset_index(drop=True)\n\n    nodes = pd.DataFrame({'id': list(set(relevant_edges['source']).union(relevant_edges['target']))})\n    nodes['node_idx'] = range(len(nodes))\n    node2idx = dict(zip(nodes['id'], nodes['node_idx']))\n\n    edge_index = torch.tensor([\n        [node2idx[s] for s in relevant_edges['source']],\n        [node2idx[t] for t in relevant_edges['target']]\n    ], dtype=torch.long)\n\n    num_nodes = len(nodes)\n    print(f\"Using {num_nodes} GO terms and {len(relevant_edges)} edges\")\n\n\n    x = torch.randn((num_nodes, embed_dim), dtype=torch.float32)\n\n\n    class SimpleGCN(nn.Module):\n        def __init__(self, in_dim, hidden_dim, out_dim):\n            super(SimpleGCN, self).__init__()\n            self.conv1 = GCNConv(in_dim, hidden_dim)\n            self.conv2 = GCNConv(hidden_dim, out_dim)\n\n        def forward(self, x, edge_index):\n            x = self.conv1(x, edge_index)\n            x = F.relu(x)\n            x = self.conv2(x, edge_index)\n            return x\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = SimpleGCN(embed_dim, hidden_dim, out_dim).to(device)\n\n\n    x = x.to(device)\n    edge_index = edge_index.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n    data = Data(x=x, edge_index=edge_index)\n\n    print(f\"Training on device: {device}\")\n    for epoch in range(epochs):\n        model.train()\n        optimizer.zero_grad()\n        embeddings = model(data.x, data.edge_index)\n        # Inner product decoder\n        recon = torch.sigmoid(torch.matmul(embeddings, embeddings.T))\n        adj_true = torch.zeros_like(recon)\n        adj_true[data.edge_index[0], data.edge_index[1]] = 1.0\n\n        loss = F.binary_cross_entropy(recon, adj_true)\n        loss.backward()\n        optimizer.step()\n\n        if epoch % 10 == 0 or epoch == epochs - 1:\n            print(f\"Epoch {epoch:03d} | Loss: {loss.item():.4f}\")\n\n\n    with torch.no_grad():\n        node_embeddings = model(data.x, data.edge_index).cpu().numpy()\n\n    del model, x, data, recon, adj_true\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    col_names = [f\"go_emb_{i}\" for i in range(node_embeddings.shape[1])]\n\n    emb_df = pd.DataFrame(node_embeddings, index=nodes['id'], columns=col_names)\n    print(f\"Created embeddings for {len(emb_df)} GO terms\")\n    return emb_df\n\n\n\n","metadata":{"id":"2m-aaVT0ZigK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sampled_data = sample_tsv(term_path, sample_frac=0.05)\ngo_terms = sampled_data['term'].unique()\nembeddings_df = create_go_embeddings_optimized(obo_path, go_terms)\nseq_df = extract_sequences(fasta_path, sampled_data['EntryID'])","metadata":{"id":"kL3g8zaoZ-0e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Combine GO embedding and PLM embedding into one dataset","metadata":{"id":"Rs5c-b4jjE_C"}},{"cell_type":"code","source":"def combine_go_protein_embeddings(sampled_data, go_emb_df, prot_emb_df):\n\n    combined = sampled_data.merge(go_emb_df, how='left', left_on='term', right_index=True)\n\n    combined = combined.merge(prot_emb_df, how='left', left_on='EntryID', right_index=True)\n\n    return combined\n\n\nmultimodal_df = combine_go_protein_embeddings(sampled_data, embeddings_df, prot_emb_df)\n\nprint(\"Multimodal feature dataframe shape:\", multimodal_df.shape)\nprint(multimodal_df.head())","metadata":{"id":"0mV_c_ALcisR","trusted":true},"outputs":[],"execution_count":null}]}